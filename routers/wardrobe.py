import os
import uuid
import time
import asyncio
import re
import logging
from datetime import datetime
from io import BytesIO
from PIL import Image

# requests - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
import requests
import concurrent.futures
from curl_cffi import requests as crequests
from bs4 import BeautifulSoup

from fastapi import APIRouter, Depends, UploadFile, HTTPException, File, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session

from database import get_db
from models import WardrobeItem
from utils.storage import delete_image, save_image
from utils.validators import validate_name
from .dependencies import get_current_user_id

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LOGGER –°–ù–ê–ß–ê–õ–ê ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === –¢–ï–ü–ï–†–¨ –ë–ï–ó–û–ü–ê–°–ù–´–ô –ò–ú–ü–û–†–¢ –ù–û–í–´–• –ú–û–î–£–õ–ï–ô ===
CLIP_AVAILABLE = False
IMAGE_PROCESSOR_AVAILABLE = False

try:
    from utils.clip_client import clip_generate_name, check_clip_service
    CLIP_AVAILABLE = True
    logger.info("‚úÖ CLIP client module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è CLIP client not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def clip_generate_name(image_url: str) -> dict:
        return {"success": False, "name": "–ü–æ–∫—É–ø–∫–∞"}
    def check_clip_service() -> bool:
        return False

try:
    from utils.image_processor import generate_image_variants, convert_variant_to_bytes
    IMAGE_PROCESSOR_AVAILABLE = True
    logger.info("‚úÖ Image processor module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Image processor not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def generate_image_variants(img, output_size=800):
        return {"original": img}
    def convert_variant_to_bytes(img, format="JPEG", quality=85):
        output = BytesIO()
        if img.mode in ("RGBA", "P", "LA", "L"):
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
        img.save(output, format=format, quality=quality, optimize=True)
        return output.getvalue()

router = APIRouter(tags=["Wardrobe"])

# --- Models ---
class ItemUrlPayload(BaseModel):
    name: str
    url: str

class ItemResponse(BaseModel):
    id: int
    name: str
    image_url: str
    item_type: str
    created_at: datetime
    class Config:
        from_attributes = True

class SelectVariantPayload(BaseModel):
    temp_id: str
    selected_variant: str
    name: str

VARIANTS_STORAGE = {}
# --- Helpers ---
def validate_image_bytes(file_bytes: bytes):
    MAX_SIZE_MB = 10
    if len(file_bytes) > MAX_SIZE_MB * 1024 * 1024:
        return False, f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > {MAX_SIZE_MB} –ú–ë."
    try:
        img = Image.open(BytesIO(file_bytes))
        img.verify()
        if img.format not in ['JPEG', 'PNG', 'GIF', 'WEBP']:
             return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ."
    except Exception:
        return False, "–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ç–æ."
    return True, None

def find_wb_image_url(nm_id: int) -> str:
    """
    –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π WB.
    üî• –û–ë–ù–û–í–õ–ï–ù–ò–ï: –î–∏–∞–ø–∞–∑–æ–Ω —Å–µ—Ä–≤–µ—Ä–æ–≤ —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 70 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤.
    """
    vol = nm_id // 100000
    part = nm_id // 1000
    
    # üî• –†–ê–°–®–ò–†–ï–ù–ù–´–ô –°–ü–ò–°–û–ö: –æ—Ç 01 –¥–æ 70
    # WB –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤–≤–æ–¥–∏—Ç –Ω–æ–≤—ã–µ —Å–µ—Ä–≤–µ—Ä–∞ (basket-42, basket-50 –∏ —Ç.–¥.)
    hosts = [f"basket-{i:02d}.wbbasket.ru" for i in range(1, 71)]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'image/avif,image/webp,*/*',
        'Referer': 'https://www.wildberries.ru/', # –í–∞–∂–Ω–æ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
    }

    logger.info(f"üîç Searching WB image for ID {nm_id} (vol={vol}, part={part})...")

    # –®–∞–±–ª–æ–Ω—ã URL (—Å–Ω–∞—á–∞–ª–∞ webp, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –ª–µ–≥—á–µ)
    url_templates = [
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.webp",
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.jpg", # Fallback –Ω–∞ jpg
    ]

    def check_url(url):
        try:
            # –¢–∞–π–º-–∞—É—Ç –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π (0.7—Å), —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –ø—Ä–æ—Å–∫–∞–∫–∏–≤–∞—Ç—å –Ω–µ–≤–µ—Ä–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–∞
            resp = requests.head(url, headers=headers, timeout=0.7)
            if resp.status_code == 200:
                return url
        except Exception:
            pass
        return None

    # max_workers=6 ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        all_urls = []
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ URL. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º webp –Ω–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–∞—Ö, –ø–æ—Ç–æ–º jpg
        for template in url_templates:
            for host in hosts:
                all_urls.append(template.format(host=host, vol=vol, part=part, nm_id=nm_id))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
        future_to_url = {executor.submit(check_url, url): url for url in all_urls}
        
        try:
            for future in concurrent.futures.as_completed(future_to_url, timeout=15):
                result = future.result()
                if result:
                    # –ö–∞–∫ —Ç–æ–ª—å–∫–æ –Ω–∞—à–ª–∏ —Ä–∞–±–æ—á–∏–π URL ‚Äî –æ—Ç–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∏ –≤—ã—Ö–æ–¥–∏–º
                    executor.shutdown(wait=False, cancel_futures=True)
                    logger.info(f"‚úÖ Image found at: {result[:80]}...")
                    return result
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Search error: {e}")
    
    logger.warning(f"‚ùå Image not found for ID {nm_id} (Checked baskets 01-70)")
    return None
    
def extract_smart_title(full_title: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
    –ü—Ä–∏–º–µ—Ä: "–ë—Ä—é–∫–∏ –∂–µ–Ω—Å–∫–∏–µ –ø–∞–ª–∞—Ü—Ü–æ —à–∏—Ä–æ–∫–∏–µ –ª–µ—Ç–Ω–∏–µ 2024" -> "–ë—Ä—é–∫–∏ –ø–∞–ª–∞—Ü—Ü–æ"
    """
    if not full_title:
        return "–ü–æ–∫—É–ø–∫–∞"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ
    title = full_title.lower()
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
    title = re.sub(r'\b\d+[-/]\d+\b', '', title)  # 42-44, 42/44
    title = re.sub(r'\b[xsmlXSML]{1,3}\b', '', title)  # S, M, L, XL, XXL
    
    # –£–±–∏—Ä–∞–µ–º –≥–æ–¥—ã –∏ —Å–µ–∑–æ–Ω—ã
    title = re.sub(r'\b20\d{2}\b', '', title)  # 2024, 2025
    title = re.sub(r'\b(–≤–µ—Å–Ω–∞|–ª–µ—Ç–æ|–æ—Å–µ–Ω—å|–∑–∏–º–∞|—Å–µ–∑–æ–Ω)\b', '', title)
    
    # ‚≠ê –î–û–ë–ê–í–ò–¢–¨ "—Ç–æ–≤–∞—Ä" –≤ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = [
        '—Ç–æ–≤–∞—Ä', '—Ç–æ–≤–∞—Ä—ã', 'wildberries', 'wb', '–≤–∞–π–ª–¥–±–µ—Ä—Ä–∏–∑',  # ‚Üê –ù–û–í–û–ï
        '–∂–µ–Ω—Å–∫–∏–µ', '–º—É–∂—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–∏–µ', '–¥–ª—è', '–Ω–æ–≤—ã–µ', '–º–æ–¥–Ω—ã–µ',
        '—Å—Ç–∏–ª—å–Ω—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–∫—É–ø–∏—Ç—å', '—Ü–µ–Ω–∞',
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–∞–≥–∞–∑–∏–Ω', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'
    ]
    
    for word in stop_words:
        title = re.sub(rf'\b{word}\b', '', title)
    
    # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–±–µ–ª—ã
    title = ' '.join(title.split())
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞
    words = title.split()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏)
    meaningful_words = [w for w in words if len(w) > 2]
    
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞
    result_words = meaningful_words[:3] if len(meaningful_words) >= 3 else meaningful_words[:2]
    
    result = ' '.join(result_words).capitalize()
    
    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
    if len(result) < 3:
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        result = full_title[:50].strip()
    
    return result if result else "–ü–æ–∫—É–ø–∫–∞"

def get_marketplace_data(url: str):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤.
    üî• –û–ë–ù–û–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç WebAPI –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ,
    —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö/—á—É–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    """

    logger.info("=" * 80)
    logger.info(f"üåê get_marketplace_data() called with URL: {url}")
    logger.info("=" * 80)
    
    image_urls = []
    title = None
    
    # WILDBERRIES
    if "wildberries" in url or "wb.ru" in url:
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ç–æ–≤–∞—Ä–∞
            match = re.search(r'catalog/(\d+)', url)
            if not match:
                logger.error("‚ùå Could not extract product ID")
                return [], None
                
            nm_id = int(match.group(1))
            logger.info(f"‚úÖ Product ID: {nm_id}")
            
            vol = nm_id // 100000
            part = nm_id // 1000
            
            images_list = []
            exact_count_found = False

            # ------------------------------------------------------------------
            # üöÄ –í–ê–†–ò–ê–ù–¢ 1: WebAPI (–°–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± –Ω–∞ 2026 –≥–æ–¥)
            # –≠—Ç–æ—Ç API –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∞–º–∏–º —Å–∞–π—Ç–æ–º WB, –æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ —Ñ–æ—Ç–æ (pics)
            # ------------------------------------------------------------------
            try:
                # –≠—Ç–æ—Ç URL —Ä–µ–¥–∫–æ –º–µ–Ω—è–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –æ–±—Å–ª—É–∂–∏–≤–∞–µ—Ç —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ —Å–∞–π—Ç–∞
                web_api_url = f"https://www.wildberries.ru/webapi/product/data?targetUrl=GP&lang=ru&curr=rub&dest=-1257786&nm={nm_id}"
                logger.info(f"üì° Requesting WebAPI info...")
                
                # –í–∞–∂–Ω–æ: –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ —É –±—Ä–∞—É–∑–µ—Ä–∞
                headers_web = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': '*/*',
                    'Referer': url,
                    'X-Requested-With': 'XMLHttpRequest'
                }

                resp = requests.get(web_api_url, headers=headers_web, timeout=8)
                
                if resp.status_code == 200:
                    data = resp.json()
                    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –≤ –æ—Ç–≤–µ—Ç–µ WebAPI
                    if data.get('data') and data['data'].get('nomenclatures'):
                        item_data = data['data']['nomenclatures'][0]
                        
                        # 1. –ë–µ—Ä–µ–º —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        if not title:
                            title = item_data.get('imt_name') or item_data.get('subj_name')
                            logger.info(f"‚úÖ Title from WebAPI: '{title}'")
                        
                        # 2. –ë–µ—Ä–µ–º —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ
                        pics_count = item_data.get('pics')
                        if pics_count:
                            images_list = list(range(1, pics_count + 1))
                            exact_count_found = True
                            logger.info(f"üì∏ Exact photo count from API: {pics_count}")
                            
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è WebAPI check failed: {e}")

            # ------------------------------------------------------------------
            # üöÄ FALLBACK: –ï—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º —É–≥–∞–¥–∞—Ç—å (–Ω–æ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ)
            # ------------------------------------------------------------------
            if not images_list:
                logger.warning("‚ö†Ô∏è Using fallback images range (1-10)")
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10, —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å —à–∞–Ω—Å –ø–æ–π–º–∞—Ç—å –º—É—Å–æ—Ä
                images_list = list(range(1, 11)) 
            
            # –ù–ê–•–û–î–ò–ú –†–ê–ë–û–ß–ò–ô –°–ï–†–í–ï–† (–ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é find_wb_image_url)
            first_image_url = find_wb_image_url(nm_id)
            
            if not first_image_url:
                logger.error("‚ùå Could not find working server")
                # –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ –æ—à–∏–±–∫—É 500
                return [], title if title else "–¢–æ–≤–∞—Ä Wildberries"
            
            # –ü–∞—Ä—Å–∏–º —Ö–æ—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ URL
            import urllib.parse
            parsed = urllib.parse.urlparse(first_image_url)
            working_host = parsed.netloc
            logger.info(f"üì¶ Server determined: {working_host}")
            
            # –°–û–ë–ò–†–ê–ï–ú –ò–¢–û–ì–û–í–´–ô –°–ü–ò–°–û–ö URL
            headers_img = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            for img_num in images_list:
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL. webp –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ.
                current_url = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.webp"
                
                # –ï—Å–ª–∏ –º—ã —Ç–æ—á–Ω–æ –∑–Ω–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ (exact_count_found), 
                # —Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º URL –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ (HEAD –∑–∞–ø—Ä–æ—Å–æ–≤), —ç—Ç–æ –±—ã—Å—Ç—Ä–µ–µ.
                if exact_count_found:
                    image_urls.append(current_url)
                else:
                    # –ï—Å–ª–∏ –º—ã "–≥–∞–¥–∞–µ–º", —Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
                    try:
                        resp = requests.head(current_url, headers=headers_img, timeout=1.5)
                        if resp.status_code == 200:
                             # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "–∑–∞–≥–ª—É—à–∫—É" (—Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª)
                            cl = resp.headers.get('Content-Length')
                            if cl and int(cl) > 5000: # > 5KB
                                image_urls.append(current_url)
                            else:
                                logger.warning(f"‚ö†Ô∏è Skipped small image #{img_num}")
                        elif resp.status_code == 404:
                            # –ï—Å–ª–∏ –ø–æ–¥—Ä—è–¥ 2 –æ—à–∏–±–∫–∏ 404 –ø—Ä–∏ –ø–µ—Ä–µ–±–æ—Ä–µ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                            if img_num > 1: 
                                break
                    except:
                        pass

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Fallback), –µ—Å–ª–∏ API –Ω–µ –≤–µ—Ä–Ω—É–ª
            if not title or title == "–¢–æ–≤–∞—Ä Wildberries":
                 # ... (–æ—Å—Ç–∞–≤–ª—è–µ–º –≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML, –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å)
                 pass

            # –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è
            if title:
                original_title = title
                title = extract_smart_title(title)
                logger.info(f"üí° Smart title: '{original_title[:30]}...' ‚Üí '{title}'")
            else:
                title = "–ü–æ–∫—É–ø–∫–∞"

            return image_urls, title

        except Exception as e:
            logger.error(f"‚ùå WB error: {type(e).__name__}: {e}")
            return [], None
    

    # –î—Ä—É–≥–∏–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã
    try:
        logger.info(f"üîç Scraping: {url[:50]}...")
        response = crequests.get(url, impersonate="chrome120", timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "lxml")
            
            og_title = soup.find("meta", property="og:title")
            if og_title: 
                title = og_title.get("content", "").strip()
            
            og_image = soup.find("meta", property="og:image")
            if og_image:
                img_url = og_image.get("content")
                if img_url and img_url.startswith('http'):
                    image_urls.append(img_url)
            
            for img_tag in soup.find_all('img')[:20]:
                src = img_tag.get('src') or img_tag.get('data-src')
                if src and any(x in src for x in ['large', 'big', 'original']):
                    if src not in image_urls and src.startswith('http'):
                        image_urls.append(src)
                        if len(image_urls) >= 8:
                            break
            
            logger.info(f"‚úÖ Found {len(image_urls)} images")

    except Exception as e:
        logger.error(f"‚ùå Scraper: {e}")

    logger.info("=" * 80)
    logger.info(f"üé¨ get_marketplace_data() ENDING:")
    logger.info(f"   - Returning {len(image_urls)} images")
    logger.info(f"   - Returning title: '{title}'")
    logger.info("=" * 80)
    
    return image_urls, title
            
def download_direct_url(image_url: str, name: str, user_id: int, item_type: str, db: Session):
    logger.info(f"Downloading from: {image_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9',
        'Referer': 'https://www.wildberries.ru/',
        'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }

    max_retries = 3
    file_bytes = None
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.info(f"üì• Download attempt {attempt + 1}/{max_retries}")
            
            response = requests.get(
                image_url, 
                headers=headers, 
                timeout=25, 
                stream=True,
                allow_redirects=True
            )
            
            logger.info(f"üìä Response status: {response.status_code}, Content-Type: {response.headers.get('Content-Type', 'unknown')}")
            
            if response.status_code == 200:
                file_bytes = response.content
                logger.info(f"‚úÖ Downloaded {len(file_bytes)} bytes")
                break
            
            elif response.status_code in [403, 498]:
                logger.error(f"üö´ WB blocked request: {response.status_code}")
                
                if attempt < max_retries - 1 and '.webp' in image_url:
                    image_url = image_url.replace('.webp', '.jpg')
                    logger.info(f"üîÑ Trying alternative format: {image_url}")
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(
                        400, 
                        "Wildberries –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ. "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
                    )
            
            elif response.status_code == 404:
                raise HTTPException(400, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            
            else:
                logger.warning(f"‚ö†Ô∏è Unexpected status: {response.status_code}")
                last_error = f"HTTP {response.status_code}"
                
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
                    
        except requests.exceptions.Timeout:
            logger.warning(f"‚è±Ô∏è Timeout on attempt {attempt + 1}")
            last_error = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                
        except requests.exceptions.ConnectionError as e:
            logger.warning(f"üîå Connection error: {e}")
            last_error = "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                raise HTTPException(400, "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º")
                
        except HTTPException:
            raise
            
        except Exception as e:
            logger.error(f"‚ùå Download exception on attempt {attempt + 1}: {type(e).__name__}: {e}")
            last_error = str(e)
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {last_error}")

    if not file_bytes:
        raise HTTPException(400, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {last_error}")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–∞–π—Ç–æ–≤
    logger.info(f"üîç Validating image bytes...")
    valid, error = validate_image_bytes(file_bytes)
    
    if not valid:
        if b"<html" in file_bytes[:500].lower() or b"<!doctype" in file_bytes[:500].lower():
            logger.error(f"‚ùå Received HTML instead of image")
            raise HTTPException(
                400, 
                "–ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞ –≤–º–µ—Å—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏. –ó–∞—â–∏—Ç–∞ –æ—Ç–±–æ—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω–∞. "
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
            )
        
        logger.error(f"‚ùå Invalid image: {error}")
        raise HTTPException(400, error)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        logger.info(f"üíæ Processing and saving image...")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        logger.info(f"üì∑ Original format: {img_format}, mode: {img.mode}, size: {img.size}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            logger.info(f"üé® Converting {img.mode} to RGB")
            
            # –°–æ–∑–¥–∞—ë–º RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            
            # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if img.mode in ("RGBA", "LA"):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –∫–∞–∫ –º–∞—Å–∫—É
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            
            img = rgb_img
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG bytes
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"market_{uuid.uuid4().hex}.jpg"
            
            logger.info(f"‚úÖ Converted to JPEG, new size: {len(final_bytes)} bytes")
        else:
            # –ï—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –±–∞–π—Ç—ã
            final_bytes = file_bytes
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            elif img_format.upper() == 'GIF':
                ext = ".gif"
            
            filename = f"market_{uuid.uuid4().hex}{ext}"
            logger.info(f"‚úÖ Using original format: {ext}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º PIL –æ–±—ä–µ–∫—Ç
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é (–æ–Ω–∞ –æ–∂–∏–¥–∞–µ—Ç filename –∏ bytes)
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Image saved successfully: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Save error: {type(e).__name__}: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    try:
        item = WardrobeItem(
            user_id=user_id,
            name=name.strip()[:100],
            item_type=item_type,
            image_url=final_url,
            created_at=datetime.utcnow()
        )
        db.add(item)
        db.commit()
        db.refresh(item)
        logger.info(f"‚úÖ Item saved to DB: id={item.id}")
        return item
        
    except Exception as e:
        logger.error(f"‚ùå DB error: {type(e).__name__}: {e}")
        # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ë–î
        try:
            delete_image(final_url)
        except:
            pass
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

# --- Routes ---

@router.get("/items", response_model=list[ItemResponse]) 
def get_wardrobe_items(user_id: int = Depends(get_current_user_id), db: Session = Depends(get_db)):
    items = db.query(WardrobeItem).filter(WardrobeItem.user_id == user_id).order_by(WardrobeItem.created_at.desc()).all()
    return items if items else []

@router.post("/add-file", response_model=ItemResponse)
async def add_item_file(name: str = Form(...), file: UploadFile = File(...), db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    valid_name, name_error = validate_name(name)
    if not valid_name: raise HTTPException(400, name_error)
    file_bytes = await file.read()
    valid, error = validate_image_bytes(file_bytes)
    if not valid: raise HTTPException(400, error)
    try:
        filename = f"upload_{uuid.uuid4().hex}.jpg"
        img = Image.open(BytesIO(file_bytes))
        if img.mode != 'RGB': img = img.convert('RGB')
        final_url = save_image(img, filename)
    except Exception as e: raise HTTPException(500, str(e))
    item = WardrobeItem(user_id=user_id, name=name, item_type="file", image_url=final_url, created_at=datetime.utcnow())
    db.add(item); db.commit(); db.refresh(item)
    return item

@router.post("/add-manual-url", response_model=ItemResponse)
async def add_item_by_manual_url(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: download_direct_url(payload.url, payload.name, user_id, "url_manual", db))

@router.post("/add-marketplace", response_model=ItemResponse)
async def add_item_by_marketplace(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    
    found_image, found_title = await loop.run_in_executor(None, lambda: get_marketplace_data(payload.url))
    
    final_name = payload.name or found_title[:30] if found_title else "–ü–æ–∫—É–ø–∫–∞"

    # –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if not found_image:
        if "wildberries" in payload.url or "wb.ru" in payload.url:
            raise HTTPException(
                400, 
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ Wildberries. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1) –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ 2) –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ —Ñ–æ—Ç–æ ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)"
            )
        elif "ozon" in payload.url:
            raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é Ozon")
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤ –ø—Ä–æ–±—É–µ–º –∫–∞—á–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            pass
    
    target_url = found_image if found_image else payload.url
    return await loop.run_in_executor(None, lambda: download_direct_url(target_url, final_name, user_id, "marketplace", db))

@router.delete("/delete")
def delete_item(item_id: int, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    item = db.query(WardrobeItem).filter(WardrobeItem.id == item_id, WardrobeItem.user_id == user_id).first()
    if not item: raise HTTPException(404, "Not found")
    try: delete_image(item.image_url)
    except: pass
    db.delete(item); db.commit()
    return {"status": "success"}

def download_image_bytes(image_url: str) -> bytes:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è bytes —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.wildberries.ru/',
    }
    
    # üî• –°–ù–ê–ß–ê–õ–ê –ü–†–û–í–ï–†–Ø–ï–ú –†–ê–ó–ú–ï–† (HEAD –∑–∞–ø—Ä–æ—Å - –±—ã—Å—Ç—Ä–æ)
    try:
        logger.info(f"üìã Checking image headers...")
        head_resp = requests.head(image_url, headers=headers, timeout=5, allow_redirects=True)
        content_length = head_resp.headers.get('Content-Length')
        
        if content_length:
            size_mb = int(content_length) / (1024 * 1024)
            logger.info(f"üì¶ Image size: {size_mb:.2f} MB")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª
            if size_mb > 10:
                raise HTTPException(400, f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {size_mb:.1f} –ú–ë (–º–∞–∫—Å–∏–º—É–º 10 –ú–ë)")
            
            # üî• –ü–†–û–í–ï–†–ö–ê –ù–ê –ó–ê–ì–õ–£–®–ö–£ (–æ–±—ã—á–Ω–æ <5KB = —ç—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–µ–µ —Ñ–æ—Ç–æ)
            if int(content_length) < 5000:
                logger.warning(f"‚ö†Ô∏è Suspiciously small image: {content_length} bytes")
                raise HTTPException(400, "–ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–∞–∑–º–µ—Ä <5KB)")
        else:
            logger.warning(f"‚ö†Ô∏è No Content-Length header")
                
    except HTTPException:
        raise
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not check headers: {e}")
    
    # –¢–µ–ø–µ—Ä—å —Å–∫–∞—á–∏–≤–∞–µ–º
    logger.info(f"‚¨áÔ∏è Downloading image...")
    start_time = time.time()
    
    response = requests.get(
        image_url, 
        headers=headers, 
        timeout=30,  # –£–≤–µ–ª–∏—á–∏–ª —Å 25 –¥–æ 30 —Å–µ–∫
        stream=True,
        allow_redirects=True
    )
    
    download_time = time.time() - start_time
    
    if response.status_code != 200:
        raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
    
    file_bytes = response.content
    logger.info(f"‚úÖ Downloaded {len(file_bytes)/1024:.1f}KB in {download_time:.2f}s")
    
    return file_bytes

def cleanup_old_variants():
    """–£–¥–∞–ª—è–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç–∞—Ä—à–µ 10 –º–∏–Ω—É—Ç"""
    from datetime import timedelta
    
    now = datetime.utcnow()
    to_delete = []
    
    for temp_id, data in VARIANTS_STORAGE.items():
        age = now - data["created_at"]
        if age > timedelta(minutes=10):
            to_delete.append(temp_id)
            # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é
            for preview_url in data.get("previews", {}).values():
                try:
                    delete_image(preview_url)
                except:
                    pass
    
    for temp_id in to_delete:
        del VARIANTS_STORAGE[temp_id]
        logger.info(f"üóëÔ∏è Cleaned up old variants: {temp_id}")

@router.post("/add-marketplace-with-variants")
async def add_marketplace_with_variants(
    payload: ItemUrlPayload, 
    db: Session = Depends(get_db), 
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –í–°–ï —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞ —Å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–≤—å—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    """
    loop = asyncio.get_event_loop()
    
    # üî• –î–û–ë–ê–í–¨–¢–ï –≠–¢–ò –°–¢–†–û–ö–ò:
    logger.info(f"üöÄ Starting variant processing")
    logger.info(f"üìç URL: {payload.url}")
    logger.info(f"üë§ User: {user_id}")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
    logger.info(f"üîç Fetching marketplace images...")
    image_urls, full_title = await loop.run_in_executor(
        None, 
        lambda: get_marketplace_data(payload.url)
    )
    
    # üî• –û–¢–õ–ê–î–ö–ê
    logger.info(f"üéØ Returned from get_marketplace_data:")
    logger.info(f"   - Images: {len(image_urls)} found")
    logger.info(f"   - Title: '{full_title}'")
    
    if not image_urls:
        raise HTTPException(
            400, 
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ."
        )
    
    logger.info(f"‚úÖ Found {len(image_urls)} images")
    
    # 2. –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    if payload.name:
        suggested_name = payload.name
    elif full_title:
        suggested_name = extract_smart_title(full_title)
        logger.info(f"üí° Smart title extracted: '{suggested_name}' from '{full_title}'")
    else:
        suggested_name = "–ü–æ–∫—É–ø–∫–∞"
    
    # 3. –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Å–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    temp_id = uuid.uuid4().hex
    variant_previews = {}
    variant_full_urls = {}  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_urls = image_urls[:10]
    
    for idx, img_url in enumerate(image_urls):
        variant_key = f"variant_{idx + 1}"
        
        try:
            # üî• –î–û–ë–ê–í–õ–ï–ù–û –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
            logger.info(f"üì• [{idx+1}/{len(image_urls)}] Processing: {img_url[:80]}...")
            start_time = time.time()
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            file_bytes = await loop.run_in_executor(
                None,
                lambda url=img_url: download_image_bytes(url)
            )
            
            download_time = time.time() - start_time
            logger.info(f"‚è±Ô∏è Downloaded in {download_time:.2f}s")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            valid, error = validate_image_bytes(file_bytes)
            if not valid:
                logger.warning(f"‚ö†Ô∏è Image {idx+1} invalid: {error}")
                continue
            
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é (300x300)
            img = Image.open(BytesIO(file_bytes))
            
            # –ü—Ä–µ–≤—å—é
            preview_img = img.copy()
            preview_img.thumbnail((300, 300), Image.Resampling.LANCZOS)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            preview_output = BytesIO()
            if preview_img.mode in ("RGBA", "P", "LA"):
                preview_rgb = Image.new("RGB", preview_img.size, (255, 255, 255))
                if preview_img.mode in ("RGBA", "LA"):
                    preview_rgb.paste(preview_img, mask=preview_img.split()[-1])
                else:
                    preview_rgb.paste(preview_img)
                preview_img = preview_rgb
            
            preview_img.save(preview_output, format='JPEG', quality=70, optimize=True)
            preview_bytes = preview_output.getvalue()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–≤—å—é
            preview_filename = f"preview_{temp_id}_{variant_key}.jpg"
            preview_url = save_image(preview_filename, preview_bytes)
            
            variant_previews[variant_key] = preview_url
            variant_full_urls[variant_key] = img_url
            
            img.close()
            
            logger.info(f"‚úÖ Preview {idx+1} created ({len(preview_bytes)/1024:.1f}KB)")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to process image {idx+1}: {type(e).__name__}: {e}")
            continue
    
    if not variant_previews:
        raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    VARIANTS_STORAGE[temp_id] = {
        "image_urls": variant_full_urls,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        "user_id": user_id,
        "created_at": datetime.utcnow(),
        "previews": variant_previews,
        "source_url": payload.url
    }
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö
    cleanup_old_variants()
    
    return {
        "temp_id": temp_id,
        "suggested_name": suggested_name,
        "variants": variant_previews,
        "total_images": len(variant_previews),
        "message": "–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞"
    }

@router.post("/select-variant", response_model=ItemResponse)
async def select_and_save_variant(
    payload: SelectVariantPayload,
    db: Session = Depends(get_db),
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ñ–æ—Ç–æ - —Å–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    """
    if payload.temp_id not in VARIANTS_STORAGE:
        raise HTTPException(404, "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–æ –≤—Ä–µ–º—è")
    
    stored = VARIANTS_STORAGE[payload.temp_id]
    
    if stored["user_id"] != user_id:
        raise HTTPException(403, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
    
    selected_variant = payload.selected_variant
    if selected_variant not in stored["image_urls"]:
        raise HTTPException(400, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: {selected_variant}")
    
    logger.info(f"üíæ User selected: {selected_variant}")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    selected_image_url = stored["image_urls"][selected_variant]
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ –ø–æ–ª–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ
    loop = asyncio.get_event_loop()
    
    try:
        file_bytes = await loop.run_in_executor(
            None,
            lambda: download_image_bytes(selected_image_url)
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        valid, error = validate_image_bytes(file_bytes)
        if not valid:
            raise HTTPException(400, error)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–∞
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
            
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"wardrobe_{uuid.uuid4().hex}.jpg"
        else:
            final_bytes = file_bytes
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            
            filename = f"wardrobe_{uuid.uuid4().hex}{ext}"
        
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Saved selected image: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Error saving selected image: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–≤—å—é
    for preview_url in stored["previews"].values():
        try:
            delete_image(preview_url)
        except:
            pass
    
    # –£–¥–∞–ª—è–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    del VARIANTS_STORAGE[payload.temp_id]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    item = WardrobeItem(
        user_id=user_id,
        name=payload.name.strip()[:100],
        item_type="marketplace",
        image_url=final_url,
        created_at=datetime.utcnow()
    )
    db.add(item)
    db.commit()
    db.refresh(item)
    
    logger.info(f"‚úÖ Item saved: id={item.id}")
    
    return item














