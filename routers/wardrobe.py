import os
import uuid
import time
import asyncio
import re
import logging
from datetime import datetime
from io import BytesIO
from PIL import Image, ImageStat, ImageFilter

# requests - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
import requests
import concurrent.futures
from curl_cffi import requests as crequests
from bs4 import BeautifulSoup

from fastapi import APIRouter, Depends, UploadFile, HTTPException, File, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session

from database import get_db
from models import WardrobeItem
from utils.storage import delete_image, save_image
from utils.validators import validate_name
from .dependencies import get_current_user_id

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LOGGER –°–ù–ê–ß–ê–õ–ê ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === –¢–ï–ü–ï–†–¨ –ë–ï–ó–û–ü–ê–°–ù–´–ô –ò–ú–ü–û–†–¢ –ù–û–í–´–• –ú–û–î–£–õ–ï–ô ===
CLIP_AVAILABLE = False
IMAGE_PROCESSOR_AVAILABLE = False

try:
    from utils.clip_client import clip_generate_name, check_clip_service
    CLIP_AVAILABLE = True
    logger.info("‚úÖ CLIP client module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è CLIP client not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def clip_generate_name(image_url: str) -> dict:
        return {"success": False, "name": "–ü–æ–∫—É–ø–∫–∞"}
    def check_clip_service() -> bool:
        return False

try:
    from utils.image_processor import generate_image_variants, convert_variant_to_bytes
    IMAGE_PROCESSOR_AVAILABLE = True
    logger.info("‚úÖ Image processor module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Image processor not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def generate_image_variants(img, output_size=800):
        return {"original": img}
    def convert_variant_to_bytes(img, format="JPEG", quality=85):
        output = BytesIO()
        if img.mode in ("RGBA", "P", "LA", "L"):
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
        img.save(output, format=format, quality=quality, optimize=True)
        return output.getvalue()

router = APIRouter(tags=["Wardrobe"])

# --- Models ---
class ItemUrlPayload(BaseModel):
    name: str
    url: str

class ItemResponse(BaseModel):
    id: int
    name: str
    image_url: str
    item_type: str
    created_at: datetime
    class Config:
        from_attributes = True

class SelectVariantPayload(BaseModel):
    temp_id: str
    selected_variant: str
    name: str

VARIANTS_STORAGE = {}
# --- Helpers ---
def validate_image_bytes(file_bytes: bytes):
    MAX_SIZE_MB = 10
    if len(file_bytes) > MAX_SIZE_MB * 1024 * 1024:
        return False, f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > {MAX_SIZE_MB} –ú–ë."
    try:
        img = Image.open(BytesIO(file_bytes))
        img.verify()
        if img.format not in ['JPEG', 'PNG', 'GIF', 'WEBP']:
             return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ."
    except Exception:
        return False, "–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ç–æ."
    return True, None

def analyze_image_score(img: Image.Image, index: int, total_images: int) -> float:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≥–∞—Ä–¥–µ—Ä–æ–±–∞ (0-100).
    –õ–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π.
    """
    score = 100.0
    
    # 1. –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–∑–∏—Ü–∏—é (—á–µ–º –¥–∞–ª—å—à–µ, —Ç–µ–º —Ö—É–∂–µ, –∫—Ä–æ–º–µ –ø–µ—Ä–≤—ã—Ö 2-—Ö)
    if index > 1:
        score -= (index * 4)  # 3-–µ —Ñ–æ—Ç–æ: -12, 10-–µ —Ñ–æ—Ç–æ: -40
    
    # 2. –®—Ç—Ä–∞—Ñ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ñ–æ—Ç–æ (—á–∞—Å—Ç–æ —Ç–∞–±–ª–∏—Ü—ã —Ä–∞–∑–º–µ—Ä–æ–≤)
    if index >= total_images - 2 and total_images > 4:
        score -= 15

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á/–± –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    gray = img.convert("L")
    
    # 3. –î–µ—Ç–µ–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü –∏ —Ç–µ–∫—Å—Ç–∞ (Filter.FIND_EDGES)
    # –¢–∞–±–ª–∏—Ü—ã –∏–º–µ—é—Ç –æ—á–µ–Ω—å –º–Ω–æ–≥–æ —Ä–µ–∑–∫–∏—Ö –≥—Ä–∞–Ω–∏—Ü
    edges = gray.filter(ImageFilter.FIND_EDGES)
    edge_stat = ImageStat.Stat(edges)
    edge_density = edge_stat.mean[0]
    
    # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ª–∏–Ω–∏–π (—Ç–µ–∫—Å—Ç, —Ç–∞–±–ª–∏—Ü–∞, —Å–ª–æ–∂–Ω–∞—è –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞) -> —à—Ç—Ä–∞—Ñ
    if edge_density > 45: 
        score -= 30
        logger.info(f"üìâ Image {index+1}: High edge density ({edge_density:.1f}) -> Likely text/table")
        
    # 4. –î–µ—Ç–µ–∫—Ç–æ—Ä "—Å–∫—É—á–Ω—ã—Ö" —Ç–µ–∫—Å—Ç—É—Ä (–Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å)
    # –ï—Å–ª–∏ —Ñ–æ—Ç–æ - –ø—Ä–æ—Å—Ç–æ –∫—É—Å–æ–∫ —Ç–∫–∞–Ω–∏, —É –Ω–µ–≥–æ –Ω–∏–∑–∫–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è —è—Ä–∫–æ—Å—Ç–∏
    stat = ImageStat.Stat(gray)
    std_dev = stat.stddev[0]
    
    if std_dev < 15:
        score -= 25
        logger.info(f"üìâ Image {index+1}: Low detail ({std_dev:.1f}) -> Likely fabric texture")

    return score

def find_wb_image_url(nm_id: int) -> str:
    """
    –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π WB.
    üî• –û–ë–ù–û–í–õ–ï–ù–ò–ï: –î–∏–∞–ø–∞–∑–æ–Ω —Å–µ—Ä–≤–µ—Ä–æ–≤ —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 70 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤.
    """
    vol = nm_id // 100000
    part = nm_id // 1000
    
    # üî• –†–ê–°–®–ò–†–ï–ù–ù–´–ô –°–ü–ò–°–û–ö: –æ—Ç 01 –¥–æ 70
    # WB –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤–≤–æ–¥–∏—Ç –Ω–æ–≤—ã–µ —Å–µ—Ä–≤–µ—Ä–∞ (basket-42, basket-50 –∏ —Ç.–¥.)
    hosts = [f"basket-{i:02d}.wbbasket.ru" for i in range(1, 71)]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'image/avif,image/webp,*/*',
        'Referer': 'https://www.wildberries.ru/', # –í–∞–∂–Ω–æ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
    }

    logger.info(f"üîç Searching WB image for ID {nm_id} (vol={vol}, part={part})...")

    # –®–∞–±–ª–æ–Ω—ã URL (—Å–Ω–∞—á–∞–ª–∞ webp, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –ª–µ–≥—á–µ)
    url_templates = [
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.webp",
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.jpg", # Fallback –Ω–∞ jpg
    ]

    def check_url(url):
        try:
            # –¢–∞–π–º-–∞—É—Ç –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π (0.7—Å), —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –ø—Ä–æ—Å–∫–∞–∫–∏–≤–∞—Ç—å –Ω–µ–≤–µ—Ä–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–∞
            resp = requests.head(url, headers=headers, timeout=0.7)
            if resp.status_code == 200:
                return url
        except Exception:
            pass
        return None

    # max_workers=6 ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        all_urls = []
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ URL. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º webp –Ω–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–∞—Ö, –ø–æ—Ç–æ–º jpg
        for template in url_templates:
            for host in hosts:
                all_urls.append(template.format(host=host, vol=vol, part=part, nm_id=nm_id))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
        future_to_url = {executor.submit(check_url, url): url for url in all_urls}
        
        try:
            for future in concurrent.futures.as_completed(future_to_url, timeout=15):
                result = future.result()
                if result:
                    # –ö–∞–∫ —Ç–æ–ª—å–∫–æ –Ω–∞—à–ª–∏ —Ä–∞–±–æ—á–∏–π URL ‚Äî –æ—Ç–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∏ –≤—ã—Ö–æ–¥–∏–º
                    executor.shutdown(wait=False, cancel_futures=True)
                    logger.info(f"‚úÖ Image found at: {result[:80]}...")
                    return result
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Search error: {e}")
    
    logger.warning(f"‚ùå Image not found for ID {nm_id} (Checked baskets 01-70)")
    return None
    
def extract_smart_title(full_title: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
    –ü—Ä–∏–º–µ—Ä: "–ë—Ä—é–∫–∏ –∂–µ–Ω—Å–∫–∏–µ –ø–∞–ª–∞—Ü—Ü–æ —à–∏—Ä–æ–∫–∏–µ –ª–µ—Ç–Ω–∏–µ 2024" -> "–ë—Ä—é–∫–∏ –ø–∞–ª–∞—Ü—Ü–æ"
    """
    if not full_title:
        return "–ü–æ–∫—É–ø–∫–∞"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ
    title = full_title.lower()
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
    title = re.sub(r'\b\d+[-/]\d+\b', '', title)  # 42-44, 42/44
    title = re.sub(r'\b[xsmlXSML]{1,3}\b', '', title)  # S, M, L, XL, XXL
    
    # –£–±–∏—Ä–∞–µ–º –≥–æ–¥—ã –∏ —Å–µ–∑–æ–Ω—ã
    title = re.sub(r'\b20\d{2}\b', '', title)  # 2024, 2025
    title = re.sub(r'\b(–≤–µ—Å–Ω–∞|–ª–µ—Ç–æ|–æ—Å–µ–Ω—å|–∑–∏–º–∞|—Å–µ–∑–æ–Ω)\b', '', title)
    
    # ‚≠ê –î–û–ë–ê–í–ò–¢–¨ "—Ç–æ–≤–∞—Ä" –≤ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = [
        '—Ç–æ–≤–∞—Ä', '—Ç–æ–≤–∞—Ä—ã', 'wildberries', 'wb', '–≤–∞–π–ª–¥–±–µ—Ä—Ä–∏–∑',  # ‚Üê –ù–û–í–û–ï
        '–∂–µ–Ω—Å–∫–∏–µ', '–º—É–∂—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–∏–µ', '–¥–ª—è', '–Ω–æ–≤—ã–µ', '–º–æ–¥–Ω—ã–µ',
        '—Å—Ç–∏–ª—å–Ω—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–∫—É–ø–∏—Ç—å', '—Ü–µ–Ω–∞',
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–∞–≥–∞–∑–∏–Ω', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'
    ]
    
    for word in stop_words:
        title = re.sub(rf'\b{word}\b', '', title)
    
    # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–±–µ–ª—ã
    title = ' '.join(title.split())
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞
    words = title.split()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏)
    meaningful_words = [w for w in words if len(w) > 2]
    
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞
    result_words = meaningful_words[:3] if len(meaningful_words) >= 3 else meaningful_words[:2]
    
    result = ' '.join(result_words).capitalize()
    
    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
    if len(result) < 3:
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        result = full_title[:50].strip()
    
    return result if result else "–ü–æ–∫—É–ø–∫–∞"

def get_marketplace_data(url: str):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç WebAPI –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ.
    """
    logger.info(f"üåê Processing URL: {url}")
    
    image_urls = []
    title = None
    
    if "wildberries" in url or "wb.ru" in url:
        try:
            match = re.search(r'catalog/(\d+)', url)
            if not match: return [], None
            nm_id = int(match.group(1))
            
            vol = nm_id // 100000
            part = nm_id // 1000
            
            # --- –®–ê–ì 1: –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ—á–Ω–æ–µ –∫–æ–ª-–≤–æ —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ WebAPI ---
            exact_count = 0
            try:
                # –ò–º–∏—Ç–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –±—Ä–∞—É–∑–µ—Ä–∞ –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º—É API WB
                web_url = f"https://www.wildberries.ru/webapi/product/data?nm={nm_id}"
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    "Accept": "*/*",
                    "X-Requested-With": "XMLHttpRequest"
                }
                res = requests.get(web_url, headers=headers, timeout=5)
                if res.status_code == 200:
                    data = res.json()
                    # –î–æ—Å—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ (–ø–æ–ª–µ pics)
                    nom = data.get('data', {}).get('nomenclatures', [{}])[0]
                    exact_count = nom.get('pics', 0)
                    if not title:
                        title = nom.get('imt_name') or nom.get('subj_name')
                    logger.info(f"‚úÖ WebAPI: found {exact_count} official photos")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è WebAPI failed, falling back to discovery: {e}")

            # --- –®–ê–ì 2: –ü–æ–∏—Å–∫ —Ä–∞–±–æ—á–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ ---
            base_url_found = find_wb_image_url(nm_id)
            if not base_url_found:
                return [], title
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–æ—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, basket-10.wbbasket.ru)
            host = re.search(r'basket-\d+\.wbbasket\.ru', base_url_found).group(0)

            # --- –®–ê–ì 3: –°–±–æ—Ä —Å—Å—ã–ª–æ–∫ ---
            if exact_count > 0:
                # –ï—Å–ª–∏ –∑–Ω–∞–µ–º —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏
                for i in range(1, exact_count + 1):
                    image_urls.append(f"https://{host}/vol{vol}/part{part}/{nm_id}/images/big/{i}.webp")
            else:
                # –ï—Å–ª–∏ API –ø—Ä–æ–º–æ–ª—á–∞–ª, –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Ä—É—á–Ω—É—é, –Ω–æ –û–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú–°–Ø –Ω–∞ –ø–µ—Ä–≤–æ–π –æ—à–∏–±–∫–µ
                logger.info("üîç Discovering images manually...")
                for i in range(1, 11): # –ú–∞–∫—Å–∏–º—É–º 10
                    test_url = f"https://{host}/vol{vol}/part{part}/{nm_id}/images/big/{i}.webp"
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ (HEAD)
                        r = requests.head(test_url, timeout=1.5)
                        if r.status_code == 200:
                            image_urls.append(test_url)
                        else:
                            # –ö–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç: –µ—Å–ª–∏ —Ñ–æ—Ç–æ #6 –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –º—ã –Ω–µ –∏–¥–µ–º –∫ #7
                            logger.info(f"üõë Stopped at photo {i} (404)")
                            break
                    except:
                        break

            return image_urls, title if title else "–¢–æ–≤–∞—Ä Wildberries"

        except Exception as e:
            logger.error(f"‚ùå WB parsing error: {e}")
            return [], None
    

    # –î—Ä—É–≥–∏–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã
    try:
        logger.info(f"üîç Scraping: {url[:50]}...")
        response = crequests.get(url, impersonate="chrome120", timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "lxml")
            
            og_title = soup.find("meta", property="og:title")
            if og_title: 
                title = og_title.get("content", "").strip()
            
            og_image = soup.find("meta", property="og:image")
            if og_image:
                img_url = og_image.get("content")
                if img_url and img_url.startswith('http'):
                    image_urls.append(img_url)
            
            for img_tag in soup.find_all('img')[:20]:
                src = img_tag.get('src') or img_tag.get('data-src')
                if src and any(x in src for x in ['large', 'big', 'original']):
                    if src not in image_urls and src.startswith('http'):
                        image_urls.append(src)
                        if len(image_urls) >= 8:
                            break
            
            logger.info(f"‚úÖ Found {len(image_urls)} images")

    except Exception as e:
        logger.error(f"‚ùå Scraper: {e}")

    logger.info("=" * 80)
    logger.info(f"üé¨ get_marketplace_data() ENDING:")
    logger.info(f"   - Returning {len(image_urls)} images")
    logger.info(f"   - Returning title: '{title}'")
    logger.info("=" * 80)
    
    return image_urls, title
            
def download_direct_url(image_url: str, name: str, user_id: int, item_type: str, db: Session):
    logger.info(f"Downloading from: {image_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9',
        'Referer': 'https://www.wildberries.ru/',
        'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }

    max_retries = 3
    file_bytes = None
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.info(f"üì• Download attempt {attempt + 1}/{max_retries}")
            
            response = requests.get(
                image_url, 
                headers=headers, 
                timeout=25, 
                stream=True,
                allow_redirects=True
            )
            
            logger.info(f"üìä Response status: {response.status_code}, Content-Type: {response.headers.get('Content-Type', 'unknown')}")
            
            if response.status_code == 200:
                file_bytes = response.content
                logger.info(f"‚úÖ Downloaded {len(file_bytes)} bytes")
                break
            
            elif response.status_code in [403, 498]:
                logger.error(f"üö´ WB blocked request: {response.status_code}")
                
                if attempt < max_retries - 1 and '.webp' in image_url:
                    image_url = image_url.replace('.webp', '.jpg')
                    logger.info(f"üîÑ Trying alternative format: {image_url}")
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(
                        400, 
                        "Wildberries –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ. "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
                    )
            
            elif response.status_code == 404:
                raise HTTPException(400, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            
            else:
                logger.warning(f"‚ö†Ô∏è Unexpected status: {response.status_code}")
                last_error = f"HTTP {response.status_code}"
                
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
                    
        except requests.exceptions.Timeout:
            logger.warning(f"‚è±Ô∏è Timeout on attempt {attempt + 1}")
            last_error = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                
        except requests.exceptions.ConnectionError as e:
            logger.warning(f"üîå Connection error: {e}")
            last_error = "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                raise HTTPException(400, "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º")
                
        except HTTPException:
            raise
            
        except Exception as e:
            logger.error(f"‚ùå Download exception on attempt {attempt + 1}: {type(e).__name__}: {e}")
            last_error = str(e)
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {last_error}")

    if not file_bytes:
        raise HTTPException(400, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {last_error}")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–∞–π—Ç–æ–≤
    logger.info(f"üîç Validating image bytes...")
    valid, error = validate_image_bytes(file_bytes)
    
    if not valid:
        if b"<html" in file_bytes[:500].lower() or b"<!doctype" in file_bytes[:500].lower():
            logger.error(f"‚ùå Received HTML instead of image")
            raise HTTPException(
                400, 
                "–ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞ –≤–º–µ—Å—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏. –ó–∞—â–∏—Ç–∞ –æ—Ç–±–æ—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω–∞. "
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
            )
        
        logger.error(f"‚ùå Invalid image: {error}")
        raise HTTPException(400, error)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        logger.info(f"üíæ Processing and saving image...")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        logger.info(f"üì∑ Original format: {img_format}, mode: {img.mode}, size: {img.size}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            logger.info(f"üé® Converting {img.mode} to RGB")
            
            # –°–æ–∑–¥–∞—ë–º RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            
            # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if img.mode in ("RGBA", "LA"):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –∫–∞–∫ –º–∞—Å–∫—É
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            
            img = rgb_img
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG bytes
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"market_{uuid.uuid4().hex}.jpg"
            
            logger.info(f"‚úÖ Converted to JPEG, new size: {len(final_bytes)} bytes")
        else:
            # –ï—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –±–∞–π—Ç—ã
            final_bytes = file_bytes
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            elif img_format.upper() == 'GIF':
                ext = ".gif"
            
            filename = f"market_{uuid.uuid4().hex}{ext}"
            logger.info(f"‚úÖ Using original format: {ext}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º PIL –æ–±—ä–µ–∫—Ç
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é (–æ–Ω–∞ –æ–∂–∏–¥–∞–µ—Ç filename –∏ bytes)
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Image saved successfully: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Save error: {type(e).__name__}: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    try:
        item = WardrobeItem(
            user_id=user_id,
            name=name.strip()[:100],
            item_type=item_type,
            image_url=final_url,
            created_at=datetime.utcnow()
        )
        db.add(item)
        db.commit()
        db.refresh(item)
        logger.info(f"‚úÖ Item saved to DB: id={item.id}")
        return item
        
    except Exception as e:
        logger.error(f"‚ùå DB error: {type(e).__name__}: {e}")
        # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ë–î
        try:
            delete_image(final_url)
        except:
            pass
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

# --- Routes ---

@router.get("/items", response_model=list[ItemResponse]) 
def get_wardrobe_items(user_id: int = Depends(get_current_user_id), db: Session = Depends(get_db)):
    items = db.query(WardrobeItem).filter(WardrobeItem.user_id == user_id).order_by(WardrobeItem.created_at.desc()).all()
    return items if items else []

@router.post("/add-file", response_model=ItemResponse)
async def add_item_file(name: str = Form(...), file: UploadFile = File(...), db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    valid_name, name_error = validate_name(name)
    if not valid_name: raise HTTPException(400, name_error)
    file_bytes = await file.read()
    valid, error = validate_image_bytes(file_bytes)
    if not valid: raise HTTPException(400, error)
    try:
        filename = f"upload_{uuid.uuid4().hex}.jpg"
        img = Image.open(BytesIO(file_bytes))
        if img.mode != 'RGB': img = img.convert('RGB')
        final_url = save_image(img, filename)
    except Exception as e: raise HTTPException(500, str(e))
    item = WardrobeItem(user_id=user_id, name=name, item_type="file", image_url=final_url, created_at=datetime.utcnow())
    db.add(item); db.commit(); db.refresh(item)
    return item

@router.post("/add-manual-url", response_model=ItemResponse)
async def add_item_by_manual_url(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: download_direct_url(payload.url, payload.name, user_id, "url_manual", db))

@router.post("/add-marketplace", response_model=ItemResponse)
async def add_item_by_marketplace(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    
    found_image, found_title = await loop.run_in_executor(None, lambda: get_marketplace_data(payload.url))
    
    final_name = payload.name or found_title[:30] if found_title else "–ü–æ–∫—É–ø–∫–∞"

    # –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if not found_image:
        if "wildberries" in payload.url or "wb.ru" in payload.url:
            raise HTTPException(
                400, 
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ Wildberries. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1) –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ 2) –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ —Ñ–æ—Ç–æ ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)"
            )
        elif "ozon" in payload.url:
            raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é Ozon")
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤ –ø—Ä–æ–±—É–µ–º –∫–∞—á–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            pass
    
    target_url = found_image if found_image else payload.url
    return await loop.run_in_executor(None, lambda: download_direct_url(target_url, final_name, user_id, "marketplace", db))

@router.delete("/delete")
def delete_item(item_id: int, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    item = db.query(WardrobeItem).filter(WardrobeItem.id == item_id, WardrobeItem.user_id == user_id).first()
    if not item: raise HTTPException(404, "Not found")
    try: delete_image(item.image_url)
    except: pass
    db.delete(item); db.commit()
    return {"status": "success"}

def download_image_bytes(image_url: str) -> bytes:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è bytes —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.wildberries.ru/',
    }
    
    # üî• –°–ù–ê–ß–ê–õ–ê –ü–†–û–í–ï–†–Ø–ï–ú –†–ê–ó–ú–ï–† (HEAD –∑–∞–ø—Ä–æ—Å - –±—ã—Å—Ç—Ä–æ)
    try:
        logger.info(f"üìã Checking image headers...")
        head_resp = requests.head(image_url, headers=headers, timeout=5, allow_redirects=True)
        content_length = head_resp.headers.get('Content-Length')
        
        if content_length:
            size_mb = int(content_length) / (1024 * 1024)
            logger.info(f"üì¶ Image size: {size_mb:.2f} MB")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª
            if size_mb > 10:
                raise HTTPException(400, f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {size_mb:.1f} –ú–ë (–º–∞–∫—Å–∏–º—É–º 10 –ú–ë)")
            
            # üî• –ü–†–û–í–ï–†–ö–ê –ù–ê –ó–ê–ì–õ–£–®–ö–£ (–æ–±—ã—á–Ω–æ <5KB = —ç—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–µ–µ —Ñ–æ—Ç–æ)
            if int(content_length) < 5000:
                logger.warning(f"‚ö†Ô∏è Suspiciously small image: {content_length} bytes")
                raise HTTPException(400, "–ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–∞–∑–º–µ—Ä <5KB)")
        else:
            logger.warning(f"‚ö†Ô∏è No Content-Length header")
                
    except HTTPException:
        raise
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not check headers: {e}")
    
    # –¢–µ–ø–µ—Ä—å —Å–∫–∞—á–∏–≤–∞–µ–º
    logger.info(f"‚¨áÔ∏è Downloading image...")
    start_time = time.time()
    
    response = requests.get(
        image_url, 
        headers=headers, 
        timeout=30,  # –£–≤–µ–ª–∏—á–∏–ª —Å 25 –¥–æ 30 —Å–µ–∫
        stream=True,
        allow_redirects=True
    )
    
    download_time = time.time() - start_time
    
    if response.status_code != 200:
        raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
    
    file_bytes = response.content
    logger.info(f"‚úÖ Downloaded {len(file_bytes)/1024:.1f}KB in {download_time:.2f}s")
    
    return file_bytes

def cleanup_old_variants():
    """–£–¥–∞–ª—è–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç–∞—Ä—à–µ 10 –º–∏–Ω—É—Ç"""
    from datetime import timedelta
    
    now = datetime.utcnow()
    to_delete = []
    
    for temp_id, data in VARIANTS_STORAGE.items():
        age = now - data["created_at"]
        if age > timedelta(minutes=10):
            to_delete.append(temp_id)
            # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é
            for preview_url in data.get("previews", {}).values():
                try:
                    delete_image(preview_url)
                except:
                    pass
    
    for temp_id in to_delete:
        del VARIANTS_STORAGE[temp_id]
        logger.info(f"üóëÔ∏è Cleaned up old variants: {temp_id}")

@router.post("/add-marketplace-with-variants")
async def add_marketplace_with_variants(
    payload: ItemUrlPayload, 
    db: Session = Depends(get_db), 
    user_id: int = Depends(get_current_user_id)
):
    loop = asyncio.get_event_loop()
    
    logger.info(f"üöÄ Starting smart variant processing for {payload.url}")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –Ω–æ–≤—É—é —É–º–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å WebAPI)
    image_urls, full_title = await loop.run_in_executor(
        None, 
        lambda: get_marketplace_data(payload.url)
    )
    
    if not image_urls:
        raise HTTPException(400, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Ç–æ–∫, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å —Å–µ—Ä–≤–µ—Ä, 
    # –Ω–æ –±–µ—Ä–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (8), —á—Ç–æ–±—ã –±—ã–ª–æ –∏–∑ —á–µ–≥–æ –≤—ã–±—Ä–∞—Ç—å
    image_urls = image_urls[:8] 
    
    if payload.name:
        suggested_name = payload.name
    elif full_title:
        suggested_name = extract_smart_title(full_title)
    else:
        suggested_name = "–ü–æ–∫—É–ø–∫–∞"

    temp_id = uuid.uuid4().hex
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: (score, index, url, image_bytes)
    candidates = []

    # 2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏–ª–∏ –ø–æ–ª—É-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    for idx, img_url in enumerate(image_urls):
        try:
            logger.info(f"üß™ Analyzing image {idx+1}/{len(image_urls)}...")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º (–±—ã—Å—Ç—Ä–æ)
            file_bytes = await loop.run_in_executor(
                None,
                lambda url=img_url: download_image_bytes(url)
            )
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ PIL
            img = Image.open(BytesIO(file_bytes))
            
            # üî• –í–´–ß–ò–°–õ–Ø–ï–ú –û–¶–ï–ù–ö–£ –ö–ê–ß–ï–°–¢–í–ê
            quality_score = analyze_image_score(img, idx, len(image_urls))
            
            # –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –ø—Ä–µ–≤—å—é –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ —Å—Ä–∞–∑—É
            preview_img = img.copy()
            preview_img.thumbnail((300, 300), Image.Resampling.LANCZOS)
            
            preview_output = BytesIO()
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (RGBA -> RGB)
            if preview_img.mode in ("RGBA", "P", "LA"):
                preview_img = preview_img.convert("RGB")
                
            preview_img.save(preview_output, format='JPEG', quality=70)
            preview_bytes = preview_output.getvalue()
            
            candidates.append({
                "score": quality_score,
                "original_url": img_url,
                "preview_bytes": preview_bytes,
                "original_idx": idx + 1
            })
            
            img.close()
            logger.info(f"‚úÖ Image {idx+1} scored: {quality_score}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to process variant {idx+1}: {e}")
            continue

    if not candidates:
        raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    # 3. –°–û–†–¢–ò–†–û–í–ö–ê –ò –û–¢–ë–û–† –õ–£–ß–®–ò–•
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏ (–ª—É—á—à–∏–µ —Å–≤–µ—Ä—Ö—É)
    candidates.sort(key=lambda x: x["score"], reverse=True)
    
    # –ë–µ—Ä–µ–º –¢–û–ü-4 (–∏–ª–∏ –º–µ–Ω—å—à–µ, –µ—Å–ª–∏ –≤—Å–µ–≥–æ –º–∞–ª–æ)
    top_candidates = candidates[:4]
    
    # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ (–æ–±–ª–æ–∂–∫–∞ WB) –≤—ã–ø–∞–ª–æ –∏–∑ —Ç–æ–ø–∞ –∏–∑-–∑–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏, 
    # –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –Ω–∞ 1 –º–µ—Å—Ç–æ, –µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ —Å–∫–∞—á–∞–Ω–æ.
    # –≠—Ç–æ —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞, —Ç–∞–∫ –∫–∞–∫ 1-–µ —Ñ–æ—Ç–æ –Ω–∞ WB –≤ 99% —Å–ª—É—á–∞–µ–≤ —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ.
    first_img = next((c for c in candidates if c["original_idx"] == 1), None)
    if first_img and first_img not in top_candidates:
        top_candidates.pop() # –£–±–∏—Ä–∞–µ–º —Ö—É–¥—à–µ–≥–æ –∏–∑ —Ç–æ–ø–∞
        top_candidates.insert(0, first_img) # –í—Å—Ç–∞–≤–ª—è–µ–º 1-–µ —Ñ–æ—Ç–æ –≤ –Ω–∞—á–∞–ª–æ
        
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ø-4 –æ–±—Ä–∞—Ç–Ω–æ –ø–æ –∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É "–ø–æ–≤–æ—Ä–æ—Ç–∞" –º–æ–¥–µ–ª–∏
    top_candidates.sort(key=lambda x: x["original_idx"])

    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–≤—å—é –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞
    variant_previews = {}
    variant_full_urls = {}
    
    for cand in top_candidates:
        variant_key = f"variant_{cand['original_idx']}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–≤—å—é –Ω–∞ –¥–∏—Å–∫/s3
        preview_filename = f"preview_{temp_id}_{variant_key}.jpg"
        preview_url = save_image(preview_filename, cand["preview_bytes"])
        
        variant_previews[variant_key] = preview_url
        variant_full_urls[variant_key] = cand["original_url"]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    VARIANTS_STORAGE[temp_id] = {
        "image_urls": variant_full_urls,
        "user_id": user_id,
        "created_at": datetime.utcnow(),
        "previews": variant_previews,
        "source_url": payload.url
    }
    
    cleanup_old_variants()
    
    return {
        "temp_id": temp_id,
        "suggested_name": suggested_name,
        "variants": variant_previews,
        "total_images": len(variant_previews),
        "message": "–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ (–æ—Ç–æ–±—Ä–∞–Ω—ã —Å–∞–º—ã–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ)"
    }

@router.post("/select-variant", response_model=ItemResponse)
async def select_and_save_variant(
    payload: SelectVariantPayload,
    db: Session = Depends(get_db),
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ñ–æ—Ç–æ - —Å–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    """
    if payload.temp_id not in VARIANTS_STORAGE:
        raise HTTPException(404, "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–æ –≤—Ä–µ–º—è")
    
    stored = VARIANTS_STORAGE[payload.temp_id]
    
    if stored["user_id"] != user_id:
        raise HTTPException(403, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
    
    selected_variant = payload.selected_variant
    if selected_variant not in stored["image_urls"]:
        raise HTTPException(400, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: {selected_variant}")
    
    logger.info(f"üíæ User selected: {selected_variant}")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    selected_image_url = stored["image_urls"][selected_variant]
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ –ø–æ–ª–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ
    loop = asyncio.get_event_loop()
    
    try:
        file_bytes = await loop.run_in_executor(
            None,
            lambda: download_image_bytes(selected_image_url)
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        valid, error = validate_image_bytes(file_bytes)
        if not valid:
            raise HTTPException(400, error)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–∞
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
            
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"wardrobe_{uuid.uuid4().hex}.jpg"
        else:
            final_bytes = file_bytes
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            
            filename = f"wardrobe_{uuid.uuid4().hex}{ext}"
        
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Saved selected image: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Error saving selected image: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–≤—å—é
    for preview_url in stored["previews"].values():
        try:
            delete_image(preview_url)
        except:
            pass
    
    # –£–¥–∞–ª—è–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    del VARIANTS_STORAGE[payload.temp_id]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    item = WardrobeItem(
        user_id=user_id,
        name=payload.name.strip()[:100],
        item_type="marketplace",
        image_url=final_url,
        created_at=datetime.utcnow()
    )
    db.add(item)
    db.commit()
    db.refresh(item)
    
    logger.info(f"‚úÖ Item saved: id={item.id}")
    
    return item
















