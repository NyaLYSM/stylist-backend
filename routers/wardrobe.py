import os
import uuid
import time
import asyncio
import re
import logging
from datetime import datetime
from io import BytesIO
from PIL import Image

# requests - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
import requests
import concurrent.futures
from curl_cffi import requests as crequests
from bs4 import BeautifulSoup

from fastapi import APIRouter, Depends, UploadFile, HTTPException, File, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session

from database import get_db
from models import WardrobeItem
from utils.storage import delete_image, save_image
from utils.validators import validate_name
from .dependencies import get_current_user_id

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LOGGER –°–ù–ê–ß–ê–õ–ê ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === –¢–ï–ü–ï–†–¨ –ë–ï–ó–û–ü–ê–°–ù–´–ô –ò–ú–ü–û–†–¢ –ù–û–í–´–• –ú–û–î–£–õ–ï–ô ===
CLIP_AVAILABLE = False
IMAGE_PROCESSOR_AVAILABLE = False

try:
    from utils.clip_client import clip_generate_name, check_clip_service
    CLIP_AVAILABLE = True
    logger.info("‚úÖ CLIP client module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è CLIP client not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def clip_generate_name(image_url: str) -> dict:
        return {"success": False, "name": "–ü–æ–∫—É–ø–∫–∞"}
    def check_clip_service() -> bool:
        return False

try:
    from utils.image_processor import generate_image_variants, convert_variant_to_bytes
    IMAGE_PROCESSOR_AVAILABLE = True
    logger.info("‚úÖ Image processor module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Image processor not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def generate_image_variants(img, output_size=800):
        return {"original": img}
    def convert_variant_to_bytes(img, format="JPEG", quality=85):
        output = BytesIO()
        if img.mode in ("RGBA", "P", "LA", "L"):
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
        img.save(output, format=format, quality=quality, optimize=True)
        return output.getvalue()

router = APIRouter(tags=["Wardrobe"])

# --- Models ---
class ItemUrlPayload(BaseModel):
    name: str
    url: str

class ItemResponse(BaseModel):
    id: int
    name: str
    image_url: str
    item_type: str
    created_at: datetime
    class Config:
        from_attributes = True

class SelectVariantPayload(BaseModel):
    temp_id: str
    selected_variant: str
    name: str

VARIANTS_STORAGE = {}
# --- Helpers ---
def validate_image_bytes(file_bytes: bytes):
    MAX_SIZE_MB = 10
    if len(file_bytes) > MAX_SIZE_MB * 1024 * 1024:
        return False, f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > {MAX_SIZE_MB} –ú–ë."
    try:
        img = Image.open(BytesIO(file_bytes))
        img.verify()
        if img.format not in ['JPEG', 'PNG', 'GIF', 'WEBP']:
             return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ."
    except Exception:
        return False, "–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ç–æ."
    return True, None
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –Ω–æ–º–µ—Ä–∞ –ù–ê –û–î–ù–û–ú —Å–µ—Ä–≤–µ—Ä–µ
    def check_image(img_num):
        url_jpg = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.jpg"
        url_webp = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.webp"
        
        for url in [url_jpg, url_webp]:
            try:
                resp = requests.head(url, headers=headers, timeout=1)
                if resp.status_code == 200:
                    return (img_num, url)
            except:
                continue
        
        return (img_num, None)
    
    found_images = {}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(check_image, i) for i in range(1, max_images + 1)]
        
        for future in concurrent.futures.as_completed(futures):
            img_num, url = future.result()
            if url:
                found_images[img_num] = url
                logger.info(f"  ‚úÖ Image #{img_num}")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ
    result = [found_images[i] for i in range(1, max_images + 1) if i in found_images]
    
    logger.info(f"‚úÖ Found {len(result)} images in ~3 seconds")
    return result

def find_wb_image_url(nm_id: int) -> str:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π WB —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
    """
    vol = nm_id // 100000
    part = nm_id // 1000
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ (–∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ 2025)
    hosts = [f"basket-{i:02d}.wbbasket.ru" for i in range(1, 26)]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    hosts.extend([f"basket-{i:02d}.wb.ru" for i in range(1, 13)])
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
    }

    logger.info(f"üîç Searching WB image for ID {nm_id} (vol={vol}, part={part}) on {len(hosts)} servers...")

    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã URL
    url_templates = [
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.jpg",
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/big/1.webp",
        "https://{host}/vol{vol}/part{part}/{nm_id}/images/c516x688/1.jpg",
    ]

    for template in url_templates:
        for host in hosts:
            url = template.format(host=host, vol=vol, part=part, nm_id=nm_id)
            try:
                # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π timeout –¥–ª—è Render.com (2 —Å–µ–∫ –≤–º–µ—Å—Ç–æ 0.5)
                resp = requests.head(url, headers=headers, timeout=2, allow_redirects=True)
                
                if resp.status_code == 200:
                    logger.info(f"‚úÖ Image FOUND at: {host} (template: {template.split('/')[-3]})")
                    return url
                    
                # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –æ—à–∏–±–∫–∏
                if resp.status_code in [403, 429, 498]:
                    logger.debug(f"‚ö†Ô∏è {host}: HTTP {resp.status_code}")
                    
            except requests.exceptions.Timeout:
                logger.debug(f"‚è±Ô∏è Timeout for {host}")
                continue
            except requests.exceptions.ConnectionError:
                logger.debug(f"üîå Connection error for {host}")
                continue
            except Exception as e:
                logger.debug(f"‚ùó Error for {host}: {type(e).__name__}")
                continue
            
    logger.warning(f"‚ùå Image not found on any WB server for ID {nm_id}")
    return None

def extract_smart_title(full_title: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
    –ü—Ä–∏–º–µ—Ä: "–ë—Ä—é–∫–∏ –∂–µ–Ω—Å–∫–∏–µ –ø–∞–ª–∞—Ü—Ü–æ —à–∏—Ä–æ–∫–∏–µ –ª–µ—Ç–Ω–∏–µ 2024" -> "–ë—Ä—é–∫–∏ –ø–∞–ª–∞—Ü—Ü–æ"
    """
    if not full_title:
        return "–ü–æ–∫—É–ø–∫–∞"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ
    title = full_title.lower()
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
    title = re.sub(r'\b\d+[-/]\d+\b', '', title)  # 42-44, 42/44
    title = re.sub(r'\b[xsmlXSML]{1,3}\b', '', title)  # S, M, L, XL, XXL
    
    # –£–±–∏—Ä–∞–µ–º –≥–æ–¥—ã –∏ —Å–µ–∑–æ–Ω—ã
    title = re.sub(r'\b20\d{2}\b', '', title)  # 2024, 2025
    title = re.sub(r'\b(–≤–µ—Å–Ω–∞|–ª–µ—Ç–æ|–æ—Å–µ–Ω—å|–∑–∏–º–∞|—Å–µ–∑–æ–Ω)\b', '', title)
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = [
        '–∂–µ–Ω—Å–∫–∏–µ', '–º—É–∂—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–∏–µ', '–¥–ª—è', '–Ω–æ–≤—ã–µ', '–º–æ–¥–Ω—ã–µ',
        '—Å—Ç–∏–ª—å–Ω—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–∫—É–ø–∏—Ç—å', '—Ü–µ–Ω–∞',
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–∞–≥–∞–∑–∏–Ω', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'
    ]
    
    for word in stop_words:
        title = re.sub(rf'\b{word}\b', '', title)
    
    # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–±–µ–ª—ã
    title = ' '.join(title.split())
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞
    words = title.split()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏)
    meaningful_words = [w for w in words if len(w) > 2]
    
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞
    result_words = meaningful_words[:3] if len(meaningful_words) >= 3 else meaningful_words[:2]
    
    result = ' '.join(result_words).capitalize()
    
    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
    if len(result) < 3:
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 30 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        result = full_title[:30].strip()
    
    return result if result else "–ü–æ–∫—É–ø–∫–∞"

def get_marketplace_data(url: str):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ —Å Wildberries
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ API endpoints
    """
    image_urls = []
    title = None
    
    # WILDBERRIES
    if "wildberries" in url or "wb.ru" in url:
        try:
            match = re.search(r'catalog/(\d+)', url)
            if not match:
                logger.error("‚ùå Could not extract product ID")
                return [], None
                
            nm_id = int(match.group(1))
            logger.info(f"‚úÖ Product ID: {nm_id}")
            
            vol = nm_id // 100000
            part = nm_id // 1000
            
            # üî• –ü–†–û–ë–£–ï–ú –ù–ï–°–ö–û–õ–¨–ö–û API ENDPOINTS
            images_list = []
            
            # API 1: –û—Å–Ω–æ–≤–Ω–æ–π (card.wb.ru)
            try:
                api_url = f"https://card.wb.ru/cards/v2/detail?appType=1&curr=rub&dest=-1257786&spp=30&nm={nm_id}"
                logger.info(f"üì° Trying API v2: {api_url}")
                resp = requests.get(api_url, timeout=10)
                logger.info(f"üì° API v2 Status: {resp.status_code}")
                
                if resp.status_code == 200:
                    data = resp.json()
                    
                    if data.get('data', {}).get('products'):
                        product = data['data']['products'][0]
                        title = product.get('name', '')
                        logger.info(f"‚úÖ Title: {title[:60]}...")
                        
                        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
                        if 'photos' in product:
                            images_list = [p for p in product['photos'] if p]
                            logger.info(f"üì∏ Found {len(images_list)} photos in 'photos' field")
                        
                        elif 'media' in product and 'images' in product['media']:
                            raw = product['media']['images']
                            if isinstance(raw, list):
                                for img in raw:
                                    if isinstance(img, dict):
                                        num = img.get('big') or img.get('c516x688')
                                        if num:
                                            images_list.append(num)
                                    else:
                                        images_list.append(img)
                            logger.info(f"üì∏ Found {len(images_list)} images in 'media.images'")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è API v2 failed: {e}")
            
            # API 2: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π (–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥)
            if not images_list:
                try:
                    api_url = f"https://basket-{vol % 10 + 1:02d}.wbbasket.ru/vol{vol}/part{part}/{nm_id}/info/ru/card.json"
                    logger.info(f"üì° Trying product JSON: {api_url[:80]}...")
                    resp = requests.get(api_url, timeout=10)
                    logger.info(f"üì° Product JSON Status: {resp.status_code}")
                    
                    if resp.status_code == 200:
                        data = resp.json()
                        
                        if 'nm_colors_names' in data:
                            title = data.get('imt_name', '')
                            logger.info(f"‚úÖ Title from JSON: {title[:60]}...")
                        
                        # –ò—â–µ–º –º–µ–¥–∏–∞ —Ñ–∞–π–ª—ã
                        if 'media' in data and 'photo_count' in data['media']:
                            photo_count = data['media']['photo_count']
                            images_list = list(range(1, min(photo_count + 1, 16)))
                            logger.info(f"üì∏ JSON says {photo_count} photos")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Product JSON failed: {e}")
            
            # Fallback: –ø—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–±–æ—Ä 1-15
            if not images_list:
                logger.warning("‚ö†Ô∏è All APIs failed, using fallback (1-15)")
                images_list = list(range(1, 16))
            
            logger.info(f"üì∏ Images to check: {images_list[:10]}")
            
            # üî• –ù–ê–•–û–î–ò–ú –†–ê–ë–û–ß–ò–ô –°–ï–†–í–ï–†
            first_image_url = find_wb_image_url(nm_id)
            
            if not first_image_url:
                logger.error("‚ùå Could not find working server")
                return [], None
            
            import urllib.parse
            parsed = urllib.parse.urlparse(first_image_url)
            working_host = parsed.netloc
            
            logger.info(f"üì¶ Server: {working_host}")
            
            # üî• –ü–†–û–í–ï–†–Ø–ï–ú –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –° –ú–Ø–ì–ö–ò–ú –§–ò–õ–¨–¢–†–û–ú
            all_images = []
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            for img_num in images_list:
                possible_urls = [
                    f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.webp",
                    f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.jpg",
                ]
                
                for test_url in possible_urls:
                    try:
                        resp = requests.head(test_url, headers=headers, timeout=3, allow_redirects=False)
                        
                        if resp.status_code == 200:
                            content_length = resp.headers.get('Content-Length')
                            
                            if content_length:
                                size_kb = int(content_length) / 1024
                                
                                # üî• –ú–Ø–ì–ö–ò–ô –§–ò–õ–¨–¢–†: –æ—Ç 10KB –¥–æ 10MB
                                # (Wildberries –º–æ–∂–µ—Ç —Å–∂–∏–º–∞—Ç—å webp –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ)
                                if size_kb < 10:
                                    logger.debug(f"‚ö†Ô∏è #{img_num} too small ({size_kb:.1f}KB)")
                                    continue
                                
                                if size_kb > 10000:
                                    logger.debug(f"‚ö†Ô∏è #{img_num} too large ({size_kb:.1f}KB)")
                                    continue
                                
                                all_images.append({
                                    'url': test_url,
                                    'num': img_num,
                                    'size': size_kb
                                })
                                logger.info(f"‚úÖ Image #{img_num} ({size_kb:.1f}KB)")
                                break
                                
                    except Exception as e:
                        logger.debug(f"üîç #{img_num}: {type(e).__name__}")
                        continue
            
            if not all_images:
                logger.error("‚ùå No images found")
                return [], None
            
            # üî• –ë–ï–†–Å–ú –ü–ï–†–í–´–ï 4 (–æ–Ω–∏ –∏–¥—É—Ç –≤ –ø–æ—Ä—è–¥–∫–µ 1,2,3,4... —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ WB)
            selected = all_images[:4]
            image_urls = [img['url'] for img in selected]
            
            logger.info(f"‚úÖ Selected {len(image_urls)} images: " + 
                       ", ".join([f"#{img['num']}({img['size']:.0f}KB)" for img in selected]))
            
            if title:
                title = extract_smart_title(title)
            else:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                try:
                    response = crequests.get(url, impersonate="chrome120", timeout=8)
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, "lxml")
                        og_title = soup.find("meta", property="og:title")
                        if og_title:
                            title = og_title.get("content", "").strip()
                            title = extract_smart_title(title)
                except:
                    pass
                
                if not title:
                    title = "–¢–æ–≤–∞—Ä Wildberries"
            
            return image_urls, title
                
        except Exception as e:
            logger.error(f"‚ùå WB error: {type(e).__name__}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return [], None

    # –î—Ä—É–≥–∏–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    try:
        logger.info(f"üîç Scraping: {url[:50]}...")
        response = crequests.get(url, impersonate="chrome120", timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "lxml")
            
            og_title = soup.find("meta", property="og:title")
            if og_title: 
                title = og_title.get("content", "").strip()
            
            og_image = soup.find("meta", property="og:image")
            if og_image:
                img_url = og_image.get("content")
                if img_url and img_url.startswith('http'):
                    image_urls.append(img_url)
            
            for img_tag in soup.find_all('img')[:20]:
                src = img_tag.get('src') or img_tag.get('data-src')
                if src and any(x in src for x in ['large', 'big', 'original']):
                    if src not in image_urls and src.startswith('http'):
                        image_urls.append(src)
                        if len(image_urls) >= 8:
                            break
            
            logger.info(f"‚úÖ Found {len(image_urls)} images")

    except Exception as e:
        logger.error(f"‚ùå Scraper: {e}")
    
    return image_urls, title

def download_direct_url(image_url: str, name: str, user_id: int, item_type: str, db: Session):
    logger.info(f"Downloading from: {image_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9',
        'Referer': 'https://www.wildberries.ru/',
        'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }

    max_retries = 3
    file_bytes = None
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.info(f"üì• Download attempt {attempt + 1}/{max_retries}")
            
            response = requests.get(
                image_url, 
                headers=headers, 
                timeout=25, 
                stream=True,
                allow_redirects=True
            )
            
            logger.info(f"üìä Response status: {response.status_code}, Content-Type: {response.headers.get('Content-Type', 'unknown')}")
            
            if response.status_code == 200:
                file_bytes = response.content
                logger.info(f"‚úÖ Downloaded {len(file_bytes)} bytes")
                break
            
            elif response.status_code in [403, 498]:
                logger.error(f"üö´ WB blocked request: {response.status_code}")
                
                if attempt < max_retries - 1 and '.webp' in image_url:
                    image_url = image_url.replace('.webp', '.jpg')
                    logger.info(f"üîÑ Trying alternative format: {image_url}")
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(
                        400, 
                        "Wildberries –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ. "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
                    )
            
            elif response.status_code == 404:
                raise HTTPException(400, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            
            else:
                logger.warning(f"‚ö†Ô∏è Unexpected status: {response.status_code}")
                last_error = f"HTTP {response.status_code}"
                
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
                    
        except requests.exceptions.Timeout:
            logger.warning(f"‚è±Ô∏è Timeout on attempt {attempt + 1}")
            last_error = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                
        except requests.exceptions.ConnectionError as e:
            logger.warning(f"üîå Connection error: {e}")
            last_error = "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                raise HTTPException(400, "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º")
                
        except HTTPException:
            raise
            
        except Exception as e:
            logger.error(f"‚ùå Download exception on attempt {attempt + 1}: {type(e).__name__}: {e}")
            last_error = str(e)
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {last_error}")

    if not file_bytes:
        raise HTTPException(400, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {last_error}")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–∞–π—Ç–æ–≤
    logger.info(f"üîç Validating image bytes...")
    valid, error = validate_image_bytes(file_bytes)
    
    if not valid:
        if b"<html" in file_bytes[:500].lower() or b"<!doctype" in file_bytes[:500].lower():
            logger.error(f"‚ùå Received HTML instead of image")
            raise HTTPException(
                400, 
                "–ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞ –≤–º–µ—Å—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏. –ó–∞—â–∏—Ç–∞ –æ—Ç–±–æ—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω–∞. "
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
            )
        
        logger.error(f"‚ùå Invalid image: {error}")
        raise HTTPException(400, error)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        logger.info(f"üíæ Processing and saving image...")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        logger.info(f"üì∑ Original format: {img_format}, mode: {img.mode}, size: {img.size}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            logger.info(f"üé® Converting {img.mode} to RGB")
            
            # –°–æ–∑–¥–∞—ë–º RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            
            # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if img.mode in ("RGBA", "LA"):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –∫–∞–∫ –º–∞—Å–∫—É
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            
            img = rgb_img
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG bytes
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"market_{uuid.uuid4().hex}.jpg"
            
            logger.info(f"‚úÖ Converted to JPEG, new size: {len(final_bytes)} bytes")
        else:
            # –ï—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –±–∞–π—Ç—ã
            final_bytes = file_bytes
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            elif img_format.upper() == 'GIF':
                ext = ".gif"
            
            filename = f"market_{uuid.uuid4().hex}{ext}"
            logger.info(f"‚úÖ Using original format: {ext}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º PIL –æ–±—ä–µ–∫—Ç
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é (–æ–Ω–∞ –æ–∂–∏–¥–∞–µ—Ç filename –∏ bytes)
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Image saved successfully: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Save error: {type(e).__name__}: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    try:
        item = WardrobeItem(
            user_id=user_id,
            name=name.strip()[:100],
            item_type=item_type,
            image_url=final_url,
            created_at=datetime.utcnow()
        )
        db.add(item)
        db.commit()
        db.refresh(item)
        logger.info(f"‚úÖ Item saved to DB: id={item.id}")
        return item
        
    except Exception as e:
        logger.error(f"‚ùå DB error: {type(e).__name__}: {e}")
        # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ë–î
        try:
            delete_image(final_url)
        except:
            pass
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

# --- Routes ---

@router.get("/items", response_model=list[ItemResponse]) 
def get_wardrobe_items(user_id: int = Depends(get_current_user_id), db: Session = Depends(get_db)):
    items = db.query(WardrobeItem).filter(WardrobeItem.user_id == user_id).order_by(WardrobeItem.created_at.desc()).all()
    return items if items else []

@router.post("/add-file", response_model=ItemResponse)
async def add_item_file(name: str = Form(...), file: UploadFile = File(...), db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    valid_name, name_error = validate_name(name)
    if not valid_name: raise HTTPException(400, name_error)
    file_bytes = await file.read()
    valid, error = validate_image_bytes(file_bytes)
    if not valid: raise HTTPException(400, error)
    try:
        filename = f"upload_{uuid.uuid4().hex}.jpg"
        img = Image.open(BytesIO(file_bytes))
        if img.mode != 'RGB': img = img.convert('RGB')
        final_url = save_image(img, filename)
    except Exception as e: raise HTTPException(500, str(e))
    item = WardrobeItem(user_id=user_id, name=name, item_type="file", image_url=final_url, created_at=datetime.utcnow())
    db.add(item); db.commit(); db.refresh(item)
    return item

@router.post("/add-manual-url", response_model=ItemResponse)
async def add_item_by_manual_url(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: download_direct_url(payload.url, payload.name, user_id, "url_manual", db))

@router.post("/add-marketplace", response_model=ItemResponse)
async def add_item_by_marketplace(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    
    found_image, found_title = await loop.run_in_executor(None, lambda: get_marketplace_data(payload.url))
    
    final_name = payload.name or found_title[:30] if found_title else "–ü–æ–∫—É–ø–∫–∞"

    # –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if not found_image:
        if "wildberries" in payload.url or "wb.ru" in payload.url:
            raise HTTPException(
                400, 
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ Wildberries. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1) –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ 2) –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ —Ñ–æ—Ç–æ ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)"
            )
        elif "ozon" in payload.url:
            raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é Ozon")
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤ –ø—Ä–æ–±—É–µ–º –∫–∞—á–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            pass
    
    target_url = found_image if found_image else payload.url
    return await loop.run_in_executor(None, lambda: download_direct_url(target_url, final_name, user_id, "marketplace", db))

@router.delete("/delete")
def delete_item(item_id: int, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    item = db.query(WardrobeItem).filter(WardrobeItem.id == item_id, WardrobeItem.user_id == user_id).first()
    if not item: raise HTTPException(404, "Not found")
    try: delete_image(item.image_url)
    except: pass
    db.delete(item); db.commit()
    return {"status": "success"}

def download_image_bytes(image_url: str) -> bytes:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è bytes —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.wildberries.ru/',
    }
    
    # üî• –°–ù–ê–ß–ê–õ–ê –ü–†–û–í–ï–†–Ø–ï–ú –†–ê–ó–ú–ï–† (HEAD –∑–∞–ø—Ä–æ—Å - –±—ã—Å—Ç—Ä–æ)
    try:
        logger.info(f"üìã Checking image headers...")
        head_resp = requests.head(image_url, headers=headers, timeout=5, allow_redirects=True)
        content_length = head_resp.headers.get('Content-Length')
        
        if content_length:
            size_mb = int(content_length) / (1024 * 1024)
            logger.info(f"üì¶ Image size: {size_mb:.2f} MB")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª
            if size_mb > 10:
                raise HTTPException(400, f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {size_mb:.1f} –ú–ë (–º–∞–∫—Å–∏–º—É–º 10 –ú–ë)")
            
            # üî• –ü–†–û–í–ï–†–ö–ê –ù–ê –ó–ê–ì–õ–£–®–ö–£ (–æ–±—ã—á–Ω–æ <5KB = —ç—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–µ–µ —Ñ–æ—Ç–æ)
            if int(content_length) < 5000:
                logger.warning(f"‚ö†Ô∏è Suspiciously small image: {content_length} bytes")
                raise HTTPException(400, "–ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–∞–∑–º–µ—Ä <5KB)")
        else:
            logger.warning(f"‚ö†Ô∏è No Content-Length header")
                
    except HTTPException:
        raise
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not check headers: {e}")
    
    # –¢–µ–ø–µ—Ä—å —Å–∫–∞—á–∏–≤–∞–µ–º
    logger.info(f"‚¨áÔ∏è Downloading image...")
    start_time = time.time()
    
    response = requests.get(
        image_url, 
        headers=headers, 
        timeout=30,  # –£–≤–µ–ª–∏—á–∏–ª —Å 25 –¥–æ 30 —Å–µ–∫
        stream=True,
        allow_redirects=True
    )
    
    download_time = time.time() - start_time
    
    if response.status_code != 200:
        raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
    
    file_bytes = response.content
    logger.info(f"‚úÖ Downloaded {len(file_bytes)/1024:.1f}KB in {download_time:.2f}s")
    
    return file_bytes

def cleanup_old_variants():
    """–£–¥–∞–ª—è–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç–∞—Ä—à–µ 10 –º–∏–Ω—É—Ç"""
    from datetime import timedelta
    
    now = datetime.utcnow()
    to_delete = []
    
    for temp_id, data in VARIANTS_STORAGE.items():
        age = now - data["created_at"]
        if age > timedelta(minutes=10):
            to_delete.append(temp_id)
            # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é
            for preview_url in data.get("previews", {}).values():
                try:
                    delete_image(preview_url)
                except:
                    pass
    
    for temp_id in to_delete:
        del VARIANTS_STORAGE[temp_id]
        logger.info(f"üóëÔ∏è Cleaned up old variants: {temp_id}")

@router.post("/add-marketplace-with-variants")
async def add_marketplace_with_variants(
    payload: ItemUrlPayload, 
    db: Session = Depends(get_db), 
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –í–°–ï —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞ —Å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–≤—å—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    """
    loop = asyncio.get_event_loop()
    
    # üî• –î–û–ë–ê–í–¨–¢–ï –≠–¢–ò –°–¢–†–û–ö–ò:
    logger.info(f"üöÄ Starting variant processing")
    logger.info(f"üìç URL: {payload.url}")
    logger.info(f"üë§ User: {user_id}")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
    logger.info(f"üîç Fetching marketplace images...")
    image_urls, full_title = await loop.run_in_executor(
        None, 
        lambda: get_marketplace_data(payload.url)
    )
    
    if not image_urls:
        raise HTTPException(
            400, 
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ."
        )
    
    logger.info(f"‚úÖ Found {len(image_urls)} images")
    
    # 2. –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    if payload.name:
        suggested_name = payload.name
    elif full_title:
        suggested_name = extract_smart_title(full_title)
        logger.info(f"üí° Smart title extracted: '{suggested_name}' from '{full_title}'")
    else:
        suggested_name = "–ü–æ–∫—É–ø–∫–∞"
    
    # 3. –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Å–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    temp_id = uuid.uuid4().hex
    variant_previews = {}
    variant_full_urls = {}  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_urls = image_urls[:10]
    
    for idx, img_url in enumerate(image_urls):
        variant_key = f"variant_{idx + 1}"
        
        try:
            # üî• –î–û–ë–ê–í–õ–ï–ù–û –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
            logger.info(f"üì• [{idx+1}/{len(image_urls)}] Processing: {img_url[:80]}...")
            start_time = time.time()
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            file_bytes = await loop.run_in_executor(
                None,
                lambda url=img_url: download_image_bytes(url)
            )
            
            download_time = time.time() - start_time
            logger.info(f"‚è±Ô∏è Downloaded in {download_time:.2f}s")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            valid, error = validate_image_bytes(file_bytes)
            if not valid:
                logger.warning(f"‚ö†Ô∏è Image {idx+1} invalid: {error}")
                continue
            
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é (300x300)
            img = Image.open(BytesIO(file_bytes))
            
            # –ü—Ä–µ–≤—å—é
            preview_img = img.copy()
            preview_img.thumbnail((300, 300), Image.Resampling.LANCZOS)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            preview_output = BytesIO()
            if preview_img.mode in ("RGBA", "P", "LA"):
                preview_rgb = Image.new("RGB", preview_img.size, (255, 255, 255))
                if preview_img.mode in ("RGBA", "LA"):
                    preview_rgb.paste(preview_img, mask=preview_img.split()[-1])
                else:
                    preview_rgb.paste(preview_img)
                preview_img = preview_rgb
            
            preview_img.save(preview_output, format='JPEG', quality=70, optimize=True)
            preview_bytes = preview_output.getvalue()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–≤—å—é
            preview_filename = f"preview_{temp_id}_{variant_key}.jpg"
            preview_url = save_image(preview_filename, preview_bytes)
            
            variant_previews[variant_key] = preview_url
            variant_full_urls[variant_key] = img_url
            
            img.close()
            
            logger.info(f"‚úÖ Preview {idx+1} created ({len(preview_bytes)/1024:.1f}KB)")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to process image {idx+1}: {type(e).__name__}: {e}")
            continue
    
    if not variant_previews:
        raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    VARIANTS_STORAGE[temp_id] = {
        "image_urls": variant_full_urls,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        "user_id": user_id,
        "created_at": datetime.utcnow(),
        "previews": variant_previews,
        "source_url": payload.url
    }
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö
    cleanup_old_variants()
    
    return {
        "temp_id": temp_id,
        "suggested_name": suggested_name,
        "variants": variant_previews,
        "total_images": len(variant_previews),
        "message": "–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞"
    }

@router.post("/select-variant", response_model=ItemResponse)
async def select_and_save_variant(
    payload: SelectVariantPayload,
    db: Session = Depends(get_db),
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ñ–æ—Ç–æ - —Å–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    """
    if payload.temp_id not in VARIANTS_STORAGE:
        raise HTTPException(404, "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–æ –≤—Ä–µ–º—è")
    
    stored = VARIANTS_STORAGE[payload.temp_id]
    
    if stored["user_id"] != user_id:
        raise HTTPException(403, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
    
    selected_variant = payload.selected_variant
    if selected_variant not in stored["image_urls"]:
        raise HTTPException(400, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: {selected_variant}")
    
    logger.info(f"üíæ User selected: {selected_variant}")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    selected_image_url = stored["image_urls"][selected_variant]
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ –ø–æ–ª–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ
    loop = asyncio.get_event_loop()
    
    try:
        file_bytes = await loop.run_in_executor(
            None,
            lambda: download_image_bytes(selected_image_url)
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        valid, error = validate_image_bytes(file_bytes)
        if not valid:
            raise HTTPException(400, error)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–∞
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
            
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"wardrobe_{uuid.uuid4().hex}.jpg"
        else:
            final_bytes = file_bytes
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            
            filename = f"wardrobe_{uuid.uuid4().hex}{ext}"
        
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Saved selected image: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Error saving selected image: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–≤—å—é
    for preview_url in stored["previews"].values():
        try:
            delete_image(preview_url)
        except:
            pass
    
    # –£–¥–∞–ª—è–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    del VARIANTS_STORAGE[payload.temp_id]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    item = WardrobeItem(
        user_id=user_id,
        name=payload.name.strip()[:100],
        item_type="marketplace",
        image_url=final_url,
        created_at=datetime.utcnow()
    )
    db.add(item)
    db.commit()
    db.refresh(item)
    
    logger.info(f"‚úÖ Item saved: id={item.id}")
    
    return item



















