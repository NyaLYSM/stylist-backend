import os
import uuid
import time
import asyncio
import re
import logging
from datetime import datetime
from io import BytesIO
from PIL import Image

# requests - –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
import requests
import concurrent.futures
from curl_cffi import requests as crequests
from bs4 import BeautifulSoup

from fastapi import APIRouter, Depends, UploadFile, HTTPException, File, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session

from database import get_db
from models import WardrobeItem
from utils.storage import delete_image, save_image
from utils.validators import validate_name
from .dependencies import get_current_user_id

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LOGGER –°–ù–ê–ß–ê–õ–ê ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === –¢–ï–ü–ï–†–¨ –ë–ï–ó–û–ü–ê–°–ù–´–ô –ò–ú–ü–û–†–¢ –ù–û–í–´–• –ú–û–î–£–õ–ï–ô ===
CLIP_AVAILABLE = False
IMAGE_PROCESSOR_AVAILABLE = False

try:
    from utils.clip_client import clip_generate_name, check_clip_service
    CLIP_AVAILABLE = True
    logger.info("‚úÖ CLIP client module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è CLIP client not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def clip_generate_name(image_url: str) -> dict:
        return {"success": False, "name": "–ü–æ–∫—É–ø–∫–∞"}
    def check_clip_service() -> bool:
        return False

try:
    from utils.image_processor import generate_image_variants, convert_variant_to_bytes
    IMAGE_PROCESSOR_AVAILABLE = True
    logger.info("‚úÖ Image processor module loaded")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Image processor not available: {e}")
    # –ó–∞–≥–ª—É—à–∫–∏
    def generate_image_variants(img, output_size=800):
        return {"original": img}
    def convert_variant_to_bytes(img, format="JPEG", quality=85):
        output = BytesIO()
        if img.mode in ("RGBA", "P", "LA", "L"):
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
        img.save(output, format=format, quality=quality, optimize=True)
        return output.getvalue()

router = APIRouter(tags=["Wardrobe"])

# --- Models ---
class ItemUrlPayload(BaseModel):
    name: str
    url: str

class ItemResponse(BaseModel):
    id: int
    name: str
    image_url: str
    item_type: str
    created_at: datetime
    class Config:
        from_attributes = True

class SelectVariantPayload(BaseModel):
    temp_id: str
    selected_variant: str
    name: str

VARIANTS_STORAGE = {}
# --- Helpers ---
def validate_image_bytes(file_bytes: bytes):
    MAX_SIZE_MB = 10
    if len(file_bytes) > MAX_SIZE_MB * 1024 * 1024:
        return False, f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > {MAX_SIZE_MB} –ú–ë."
    try:
        img = Image.open(BytesIO(file_bytes))
        img.verify()
        if img.format not in ['JPEG', 'PNG', 'GIF', 'WEBP']:
             return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ."
    except Exception:
        return False, "–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ç–æ."
    return True, None
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –Ω–æ–º–µ—Ä–∞ –ù–ê –û–î–ù–û–ú —Å–µ—Ä–≤–µ—Ä–µ
    def check_image(img_num):
        url_jpg = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.jpg"
        url_webp = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.webp"
        
        for url in [url_jpg, url_webp]:
            try:
                resp = requests.head(url, headers=headers, timeout=1)
                if resp.status_code == 200:
                    return (img_num, url)
            except:
                continue
        
        return (img_num, None)
    
    found_images = {}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(check_image, i) for i in range(1, max_images + 1)]
        
        for future in concurrent.futures.as_completed(futures):
            img_num, url = future.result()
            if url:
                found_images[img_num] = url
                logger.info(f"  ‚úÖ Image #{img_num}")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ
    result = [found_images[i] for i in range(1, max_images + 1) if i in found_images]
    
    logger.info(f"‚úÖ Found {len(result)} images in ~3 seconds")
    return result

def get_marketplace_data(url: str):
    """
    –ü–†–û–°–¢–ê–Ø –ò –ù–ê–î–Å–ñ–ù–ê–Ø –≤–µ—Ä—Å–∏—è
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ find_wb_image_url –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ñ–æ—Ç–æ
    –ó–∞—Ç–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏—â–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ
    """
    image_urls = []
    title = None
    
    # WILDBERRIES
    if "wildberries" in url or "wb.ru" in url:
        try:
            match = re.search(r'catalog/(\d+)', url)
            if not match:
                logger.error("‚ùå Could not extract product ID")
                return [], None
                
            nm_id = int(match.group(1))
            logger.info(f"‚úÖ Product ID: {nm_id}")
            
            vol = nm_id // 100000
            part = nm_id // 1000
            
            # –ò–°–ü–û–õ–¨–ó–£–ï–ú –ü–†–û–í–ï–†–ï–ù–ù–´–ô –ú–ï–¢–û–î –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ñ–æ—Ç–æ
            logger.info(f"üîç Searching for first image...")
            first_image = find_wb_image_url(nm_id)
            
            if not first_image:
                logger.error(f"‚ùå First image not found")
                return [], None
            
            image_urls.append(first_image)
            logger.info(f"‚úÖ First image found")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ URL
            # –ù–∞–ø—Ä–∏–º–µ—Ä: https://basket-10.wbbasket.ru/vol... -> basket-10.wbbasket.ru
            import urllib.parse
            parsed = urllib.parse.urlparse(first_image)
            working_host = parsed.netloc
            
            logger.info(f"üì¶ Using server: {working_host}")
            
            # –¢–µ–ø–µ—Ä—å –∏—â–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ –Ω–∞ –≠–¢–û–ú –ñ–ï —Å–µ—Ä–≤–µ—Ä–µ
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            # –ü—Ä–æ–±—É–µ–º –Ω–æ–º–µ—Ä–∞ 2-8 (–≤—Å–µ–≥–æ –ø–æ–ª—É—á–∏—Ç—Å—è –º–∞–∫—Å–∏–º—É–º 8 —Ñ–æ—Ç–æ)
            for img_num in range(2, 9):
                url_jpg = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.jpg"
                url_webp = f"https://{working_host}/vol{vol}/part{part}/{nm_id}/images/big/{img_num}.webp"
                
                found = False
                for test_url in [url_jpg, url_webp]:
                    try:
                        resp = requests.head(test_url, headers=headers, timeout=2)
                        if resp.status_code == 200:
                            image_urls.append(test_url)
                            logger.info(f"‚úÖ Image #{img_num} found")
                            found = True
                            break
                    except:
                        continue
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ 2 –ø–æ–¥—Ä—è–¥ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if not found and img_num > 3:
                    logger.info(f"‚èπÔ∏è Stopping search at #{img_num}")
                    break
            
            logger.info(f"‚úÖ Total: {len(image_urls)} images")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
            logger.info(f"üìù Fetching title...")
            
            # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ API (–±—ã—Å—Ç—Ä–æ)
            try:
                api_url = f"https://card.wb.ru/cards/v1/detail?appType=1&curr=rub&dest=-1257786&spp=30&nm={nm_id}"
                resp = requests.get(api_url, timeout=5)
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get('data', {}).get('products'):
                        title = data['data']['products'][0].get('name', '')
                        if title:
                            logger.info(f"‚úÖ Title from API: {title[:40]}...")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è API title failed: {e}")
            
            # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É (–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ —Ç–æ—á–Ω–æ)
            if not title:
                try:
                    response = crequests.get(url, impersonate="chrome120", timeout=8)
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, "lxml")
                        
                        og_title = soup.find("meta", property="og:title")
                        if og_title:
                            title = og_title.get("content", "").strip()
                            if title:
                                logger.info(f"‚úÖ Title from page: {title[:40]}...")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Page title failed: {e}")
            
            if not title:
                title = "–¢–æ–≤–∞—Ä Wildberries"
                logger.info(f"‚ÑπÔ∏è Using default title")
            
            return image_urls, title
                
        except Exception as e:
            logger.error(f"‚ùå WB error: {type(e).__name__}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return [], None

    # –î—Ä—É–≥–∏–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã
    try:
        logger.info(f"üîç Scraping: {url[:50]}...")
        response = crequests.get(url, impersonate="chrome120", timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "lxml")
            
            og_title = soup.find("meta", property="og:title")
            if og_title: 
                title = og_title.get("content", "").strip()
            
            og_image = soup.find("meta", property="og:image")
            if og_image:
                img_url = og_image.get("content")
                if img_url and img_url.startswith('http'):
                    image_urls.append(img_url)
            
            for img_tag in soup.find_all('img')[:20]:  # –ü–µ—Ä–≤—ã–µ 20 img —Ç–µ–≥–æ–≤
                src = img_tag.get('src') or img_tag.get('data-src')
                if src and any(x in src for x in ['large', 'big', 'original']):
                    if src not in image_urls and src.startswith('http'):
                        image_urls.append(src)
                        if len(image_urls) >= 8:
                            break
            
            logger.info(f"‚úÖ Found {len(image_urls)} images")

    except Exception as e:
        logger.error(f"‚ùå Scraper: {e}")
    
    return image_urls, title
    
def extract_smart_title(full_title: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
    –ü—Ä–∏–º–µ—Ä: "–ë—Ä—é–∫–∏ –∂–µ–Ω—Å–∫–∏–µ –ø–∞–ª–∞—Ü—Ü–æ —à–∏—Ä–æ–∫–∏–µ –ª–µ—Ç–Ω–∏–µ 2024" -> "–ë—Ä—é–∫–∏ –ø–∞–ª–∞—Ü—Ü–æ"
    """
    if not full_title:
        return "–ü–æ–∫—É–ø–∫–∞"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ
    title = full_title.lower()
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
    title = re.sub(r'\b\d+[-/]\d+\b', '', title)  # 42-44, 42/44
    title = re.sub(r'\b[xsmlXSML]{1,3}\b', '', title)  # S, M, L, XL, XXL
    
    # –£–±–∏—Ä–∞–µ–º –≥–æ–¥—ã –∏ —Å–µ–∑–æ–Ω—ã
    title = re.sub(r'\b20\d{2}\b', '', title)  # 2024, 2025
    title = re.sub(r'\b(–≤–µ—Å–Ω–∞|–ª–µ—Ç–æ|–æ—Å–µ–Ω—å|–∑–∏–º–∞|—Å–µ–∑–æ–Ω)\b', '', title)
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = [
        '–∂–µ–Ω—Å–∫–∏–µ', '–º—É–∂—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–∏–µ', '–¥–ª—è', '–Ω–æ–≤—ã–µ', '–º–æ–¥–Ω—ã–µ',
        '—Å—Ç–∏–ª—å–Ω—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–∫—É–ø–∏—Ç—å', '—Ü–µ–Ω–∞',
        '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–∞–≥–∞–∑–∏–Ω', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'
    ]
    
    for word in stop_words:
        title = re.sub(rf'\b{word}\b', '', title)
    
    # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–±–µ–ª—ã
    title = ' '.join(title.split())
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞
    words = title.split()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏)
    meaningful_words = [w for w in words if len(w) > 2]
    
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞
    result_words = meaningful_words[:3] if len(meaningful_words) >= 3 else meaningful_words[:2]
    
    result = ' '.join(result_words).capitalize()
    
    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ
    if len(result) < 3:
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 30 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        result = full_title[:30].strip()
    
    return result if result else "–ü–æ–∫—É–ø–∫–∞"

def download_direct_url(image_url: str, name: str, user_id: int, item_type: str, db: Session):
    logger.info(f"Downloading from: {image_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9',
        'Referer': 'https://www.wildberries.ru/',
        'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }

    max_retries = 3
    file_bytes = None
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.info(f"üì• Download attempt {attempt + 1}/{max_retries}")
            
            response = requests.get(
                image_url, 
                headers=headers, 
                timeout=25, 
                stream=True,
                allow_redirects=True
            )
            
            logger.info(f"üìä Response status: {response.status_code}, Content-Type: {response.headers.get('Content-Type', 'unknown')}")
            
            if response.status_code == 200:
                file_bytes = response.content
                logger.info(f"‚úÖ Downloaded {len(file_bytes)} bytes")
                break
            
            elif response.status_code in [403, 498]:
                logger.error(f"üö´ WB blocked request: {response.status_code}")
                
                if attempt < max_retries - 1 and '.webp' in image_url:
                    image_url = image_url.replace('.webp', '.jpg')
                    logger.info(f"üîÑ Trying alternative format: {image_url}")
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(
                        400, 
                        "Wildberries –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ. "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
                    )
            
            elif response.status_code == 404:
                raise HTTPException(400, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            
            else:
                logger.warning(f"‚ö†Ô∏è Unexpected status: {response.status_code}")
                last_error = f"HTTP {response.status_code}"
                
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
                    
        except requests.exceptions.Timeout:
            logger.warning(f"‚è±Ô∏è Timeout on attempt {attempt + 1}")
            last_error = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                
        except requests.exceptions.ConnectionError as e:
            logger.warning(f"üîå Connection error: {e}")
            last_error = "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                raise HTTPException(400, "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º")
                
        except HTTPException:
            raise
            
        except Exception as e:
            logger.error(f"‚ùå Download exception on attempt {attempt + 1}: {type(e).__name__}: {e}")
            last_error = str(e)
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                raise HTTPException(400, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {last_error}")

    if not file_bytes:
        raise HTTPException(400, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {last_error}")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–∞–π—Ç–æ–≤
    logger.info(f"üîç Validating image bytes...")
    valid, error = validate_image_bytes(file_bytes)
    
    if not valid:
        if b"<html" in file_bytes[:500].lower() or b"<!doctype" in file_bytes[:500].lower():
            logger.error(f"‚ùå Received HTML instead of image")
            raise HTTPException(
                400, 
                "–ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞ –≤–º–µ—Å—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏. –ó–∞—â–∏—Ç–∞ –æ—Ç–±–æ—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω–∞. "
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)."
            )
        
        logger.error(f"‚ùå Invalid image: {error}")
        raise HTTPException(400, error)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        logger.info(f"üíæ Processing and saving image...")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        logger.info(f"üì∑ Original format: {img_format}, mode: {img.mode}, size: {img.size}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            logger.info(f"üé® Converting {img.mode} to RGB")
            
            # –°–æ–∑–¥–∞—ë–º RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            
            # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if img.mode in ("RGBA", "LA"):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –∫–∞–∫ –º–∞—Å–∫—É
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            
            img = rgb_img
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG bytes
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"market_{uuid.uuid4().hex}.jpg"
            
            logger.info(f"‚úÖ Converted to JPEG, new size: {len(final_bytes)} bytes")
        else:
            # –ï—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –±–∞–π—Ç—ã
            final_bytes = file_bytes
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            elif img_format.upper() == 'GIF':
                ext = ".gif"
            
            filename = f"market_{uuid.uuid4().hex}{ext}"
            logger.info(f"‚úÖ Using original format: {ext}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º PIL –æ–±—ä–µ–∫—Ç
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é (–æ–Ω–∞ –æ–∂–∏–¥–∞–µ—Ç filename –∏ bytes)
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Image saved successfully: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Save error: {type(e).__name__}: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    try:
        item = WardrobeItem(
            user_id=user_id,
            name=name.strip()[:100],
            item_type=item_type,
            image_url=final_url,
            created_at=datetime.utcnow()
        )
        db.add(item)
        db.commit()
        db.refresh(item)
        logger.info(f"‚úÖ Item saved to DB: id={item.id}")
        return item
        
    except Exception as e:
        logger.error(f"‚ùå DB error: {type(e).__name__}: {e}")
        # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ë–î
        try:
            delete_image(final_url)
        except:
            pass
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

# --- Routes ---

@router.get("/items", response_model=list[ItemResponse]) 
def get_wardrobe_items(user_id: int = Depends(get_current_user_id), db: Session = Depends(get_db)):
    items = db.query(WardrobeItem).filter(WardrobeItem.user_id == user_id).order_by(WardrobeItem.created_at.desc()).all()
    return items if items else []

@router.post("/add-file", response_model=ItemResponse)
async def add_item_file(name: str = Form(...), file: UploadFile = File(...), db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    valid_name, name_error = validate_name(name)
    if not valid_name: raise HTTPException(400, name_error)
    file_bytes = await file.read()
    valid, error = validate_image_bytes(file_bytes)
    if not valid: raise HTTPException(400, error)
    try:
        filename = f"upload_{uuid.uuid4().hex}.jpg"
        img = Image.open(BytesIO(file_bytes))
        if img.mode != 'RGB': img = img.convert('RGB')
        final_url = save_image(img, filename)
    except Exception as e: raise HTTPException(500, str(e))
    item = WardrobeItem(user_id=user_id, name=name, item_type="file", image_url=final_url, created_at=datetime.utcnow())
    db.add(item); db.commit(); db.refresh(item)
    return item

@router.post("/add-manual-url", response_model=ItemResponse)
async def add_item_by_manual_url(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: download_direct_url(payload.url, payload.name, user_id, "url_manual", db))

@router.post("/add-marketplace", response_model=ItemResponse)
async def add_item_by_marketplace(payload: ItemUrlPayload, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    loop = asyncio.get_event_loop()
    
    found_image, found_title = await loop.run_in_executor(None, lambda: get_marketplace_data(payload.url))
    
    final_name = payload.name or found_title[:30] if found_title else "–ü–æ–∫—É–ø–∫–∞"

    # –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    if not found_image:
        if "wildberries" in payload.url or "wb.ru" in payload.url:
            raise HTTPException(
                400, 
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ Wildberries. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1) –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ 2) –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ (–ü–ö–ú –ø–æ —Ñ–æ—Ç–æ ‚Üí –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞—Ä—Ç–∏–Ω–∫–∏)"
            )
        elif "ozon" in payload.url:
            raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é Ozon")
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤ –ø—Ä–æ–±—É–µ–º –∫–∞—á–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            pass
    
    target_url = found_image if found_image else payload.url
    return await loop.run_in_executor(None, lambda: download_direct_url(target_url, final_name, user_id, "marketplace", db))

@router.delete("/delete")
def delete_item(item_id: int, db: Session = Depends(get_db), user_id: int = Depends(get_current_user_id)):
    item = db.query(WardrobeItem).filter(WardrobeItem.id == item_id, WardrobeItem.user_id == user_id).first()
    if not item: raise HTTPException(404, "Not found")
    try: delete_image(item.image_url)
    except: pass
    db.delete(item); db.commit()
    return {"status": "success"}

def download_image_bytes(image_url: str) -> bytes:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è bytes"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': 'https://www.wildberries.ru/',
    }
    
    response = requests.get(image_url, headers=headers, timeout=25, allow_redirects=True)
    
    if response.status_code != 200:
        raise HTTPException(400, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status_code}")
    
    return response.content

def cleanup_old_variants():
    """–£–¥–∞–ª—è–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å—Ç–∞—Ä—à–µ 10 –º–∏–Ω—É—Ç"""
    from datetime import timedelta
    
    now = datetime.utcnow()
    to_delete = []
    
    for temp_id, data in VARIANTS_STORAGE.items():
        age = now - data["created_at"]
        if age > timedelta(minutes=10):
            to_delete.append(temp_id)
            # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é
            for preview_url in data.get("previews", {}).values():
                try:
                    delete_image(preview_url)
                except:
                    pass
    
    for temp_id in to_delete:
        del VARIANTS_STORAGE[temp_id]
        logger.info(f"üóëÔ∏è Cleaned up old variants: {temp_id}")

@router.post("/add-marketplace-with-variants")
async def add_marketplace_with_variants(
    payload: ItemUrlPayload, 
    db: Session = Depends(get_db), 
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –í–°–ï —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞ —Å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–≤—å—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    """
    loop = asyncio.get_event_loop()
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
    logger.info(f"üîç Fetching marketplace images...")
    image_urls, full_title = await loop.run_in_executor(
        None, 
        lambda: get_marketplace_data(payload.url)
    )
    
    if not image_urls:
        raise HTTPException(
            400, 
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ."
        )
    
    logger.info(f"‚úÖ Found {len(image_urls)} images")
    
    # 2. –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    if payload.name:
        suggested_name = payload.name
    elif full_title:
        suggested_name = extract_smart_title(full_title)
        logger.info(f"üí° Smart title extracted: '{suggested_name}' from '{full_title}'")
    else:
        suggested_name = "–ü–æ–∫—É–ø–∫–∞"
    
    # 3. –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Å–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    temp_id = uuid.uuid4().hex
    variant_previews = {}
    variant_full_urls = {}  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_urls = image_urls[:10]
    
    for idx, img_url in enumerate(image_urls):
        variant_key = f"variant_{idx + 1}"
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            file_bytes = await loop.run_in_executor(
                None,
                lambda url=img_url: download_image_bytes(url)
            )
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            valid, error = validate_image_bytes(file_bytes)
            if not valid:
                logger.warning(f"‚ö†Ô∏è Image {idx+1} invalid: {error}")
                continue
            
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–µ–≤—å—é (300x300)
            img = Image.open(BytesIO(file_bytes))
            
            # –ü—Ä–µ–≤—å—é
            preview_img = img.copy()
            preview_img.thumbnail((300, 300), Image.Resampling.LANCZOS)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            preview_output = BytesIO()
            if preview_img.mode in ("RGBA", "P", "LA"):
                preview_rgb = Image.new("RGB", preview_img.size, (255, 255, 255))
                if preview_img.mode in ("RGBA", "LA"):
                    preview_rgb.paste(preview_img, mask=preview_img.split()[-1])
                else:
                    preview_rgb.paste(preview_img)
                preview_img = preview_rgb
            
            preview_img.save(preview_output, format='JPEG', quality=70, optimize=True)
            preview_bytes = preview_output.getvalue()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–≤—å—é
            preview_filename = f"preview_{temp_id}_{variant_key}.jpg"
            preview_url = save_image(preview_filename, preview_bytes)
            
            variant_previews[variant_key] = preview_url
            variant_full_urls[variant_key] = img_url  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL
            
            img.close()
            
            logger.info(f"‚úÖ Preview {idx+1} created")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to process image {idx+1}: {e}")
            continue
    
    if not variant_previews:
        raise HTTPException(400, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    VARIANTS_STORAGE[temp_id] = {
        "image_urls": variant_full_urls,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        "user_id": user_id,
        "created_at": datetime.utcnow(),
        "previews": variant_previews,
        "source_url": payload.url
    }
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö
    cleanup_old_variants()
    
    return {
        "temp_id": temp_id,
        "suggested_name": suggested_name,
        "variants": variant_previews,
        "total_images": len(variant_previews),
        "message": "–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞"
    }

@router.post("/select-variant", response_model=ItemResponse)
async def select_and_save_variant(
    payload: SelectVariantPayload,
    db: Session = Depends(get_db),
    user_id: int = Depends(get_current_user_id)
):
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ñ–æ—Ç–æ - —Å–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    """
    if payload.temp_id not in VARIANTS_STORAGE:
        raise HTTPException(404, "–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–æ –≤—Ä–µ–º—è")
    
    stored = VARIANTS_STORAGE[payload.temp_id]
    
    if stored["user_id"] != user_id:
        raise HTTPException(403, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
    
    selected_variant = payload.selected_variant
    if selected_variant not in stored["image_urls"]:
        raise HTTPException(400, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: {selected_variant}")
    
    logger.info(f"üíæ User selected: {selected_variant}")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    selected_image_url = stored["image_urls"][selected_variant]
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ –ø–æ–ª–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ
    loop = asyncio.get_event_loop()
    
    try:
        file_bytes = await loop.run_in_executor(
            None,
            lambda: download_image_bytes(selected_image_url)
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        valid, error = validate_image_bytes(file_bytes)
        if not valid:
            raise HTTPException(400, error)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        img = Image.open(BytesIO(file_bytes))
        img_format = img.format or "JPEG"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–∞
        need_conversion = img.mode in ("RGBA", "P", "LA", "L")
        
        if need_conversion:
            rgb_img = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode in ("RGBA", "LA"):
                rgb_img.paste(img, mask=img.split()[-1])
            else:
                rgb_img.paste(img)
            img = rgb_img
            
            output = BytesIO()
            img.save(output, format='JPEG', quality=85, optimize=True)
            final_bytes = output.getvalue()
            filename = f"wardrobe_{uuid.uuid4().hex}.jpg"
        else:
            final_bytes = file_bytes
            ext = ".jpg"
            if img_format.upper() in ['JPEG', 'JPG']:
                ext = ".jpg"
            elif img_format.upper() == 'PNG':
                ext = ".png"
            elif img_format.upper() == 'WEBP':
                ext = ".webp"
            
            filename = f"wardrobe_{uuid.uuid4().hex}{ext}"
        
        img.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        final_url = save_image(filename, final_bytes)
        logger.info(f"‚úÖ Saved selected image: {final_url}")
        
    except Exception as e:
        logger.error(f"‚ùå Error saving selected image: {e}")
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–≤—å—é
    for preview_url in stored["previews"].values():
        try:
            delete_image(preview_url)
        except:
            pass
    
    # –£–¥–∞–ª—è–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    del VARIANTS_STORAGE[payload.temp_id]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    item = WardrobeItem(
        user_id=user_id,
        name=payload.name.strip()[:100],
        item_type="marketplace",
        image_url=final_url,
        created_at=datetime.utcnow()
    )
    db.add(item)
    db.commit()
    db.refresh(item)
    
    logger.info(f"‚úÖ Item saved: id={item.id}")
    
    return item












